{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh6vhNxm0bA3vG5sDLVJlw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salsabillaflsft/ABSApublic/blob/main/AspectBasedSentimentAnalysis_DASH_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "UfKXpZlPjjN-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOaXGmmgKsPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f211ae-2754-4dd4-c2db-9622f3d9af3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jupyter-dash in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: ansi2html in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (1.8.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (1.3.4)\n",
            "Requirement already satisfied: dash in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (2.9.3)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (2.2.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (5.5.6)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (7.34.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (2.27.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (1.5.6)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash->jupyter-dash) (5.0.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash->jupyter-dash) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash->jupyter-dash) (2.0.0)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash->jupyter-dash) (5.13.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->jupyter-dash) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->jupyter-dash) (8.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->jupyter-dash) (3.1.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->jupyter-dash) (2.3.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter-dash) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter-dash) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter-dash) (6.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (4.8.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (0.18.2)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (3.0.38)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (67.7.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (2.14.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (4.4.2)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (0.1.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->jupyter-dash) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->jupyter-dash) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->jupyter-dash) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->jupyter-dash) (3.4)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->jupyter-dash) (1.16.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->jupyter-dash) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask->jupyter-dash) (2.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->jupyter-dash) (0.7.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash->jupyter-dash) (8.2.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash) (0.2.6)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (5.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (23.2.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->jupyter-dash) (3.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dash-bootstrap-components in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: dash>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash-bootstrap-components) (2.9.3)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash-bootstrap-components) (2.2.4)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash-bootstrap-components) (2.0.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash-bootstrap-components) (2.0.0)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash-bootstrap-components) (5.13.1)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash-bootstrap-components) (5.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->dash>=2.0.0->dash-bootstrap-components) (3.1.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->dash>=2.0.0->dash-bootstrap-components) (2.3.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->dash>=2.0.0->dash-bootstrap-components) (8.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->dash>=2.0.0->dash-bootstrap-components) (2.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.0.0->dash-bootstrap-components) (8.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.0.4->dash>=2.0.0->dash-bootstrap-components) (2.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dash-bootstrap-templates in /usr/local/lib/python3.10/dist-packages (1.0.8)\n",
            "Requirement already satisfied: dash-bootstrap-components>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from dash-bootstrap-templates) (1.4.1)\n",
            "Requirement already satisfied: dash in /usr/local/lib/python3.10/dist-packages (from dash-bootstrap-templates) (2.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dash-bootstrap-templates) (1.22.4)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash->dash-bootstrap-templates) (2.0.0)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash->dash-bootstrap-templates) (2.2.4)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash->dash-bootstrap-templates) (5.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash->dash-bootstrap-templates) (2.0.0)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash->dash-bootstrap-templates) (5.13.1)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->dash->dash-bootstrap-templates) (8.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->dash->dash-bootstrap-templates) (2.1.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->dash->dash-bootstrap-templates) (3.1.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->dash->dash-bootstrap-templates) (2.3.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash->dash-bootstrap-templates) (8.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.0.4->dash->dash-bootstrap-templates) (2.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install jupyter-dash\n",
        "!pip install dash-bootstrap-components  \n",
        "!pip install dash-bootstrap-templates\n",
        "# !pip install pyngrok\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "KT3floJrjl8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import dash\n",
        "import dash_bootstrap_components as dbc\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from dash import html, dcc\n",
        "from dash.dependencies import Input, Output, State\n",
        "from jupyter_dash import JupyterDash\n",
        "from dash_bootstrap_templates import ThemeChangerAIO, template_from_url\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import optim, nn\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# from pyngrok import ngrok\n",
        "\n",
        "from transformers import BertTokenizer, BertConfig, BertForPreTraining, BertPreTrainedModel, BertModel"
      ],
      "metadata": {
        "id": "l9asCOFnKvOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/TA/Dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iun1tJe4K8Vl",
        "outputId": "ab44584e-21f8-4145-c442-37caf32deb28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/TA/Dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "  print('there are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "  print('we will use the GPU: ', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "  print(\"No GPU available, using the CPU instead\")\n",
        "  device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB9xiUjgRhwq",
        "outputId": "d859a7aa-21db-4602-caf8-d2d7da7055f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are 1 GPU(s) available.\n",
            "we will use the GPU:  Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load "
      ],
      "metadata": {
        "id": "Nq_fFDgIQ055"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model"
      ],
      "metadata": {
        "id": "OdPXTU39T3Ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForMultiLabelClassification(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels_list\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob) #0.1\n",
        "        # self.dropout = nn.Dropout(p=0.5)\n",
        "        self.classifiers = nn.ModuleList([nn.Linear(config.hidden_size, num_label) for num_label in self.num_labels])\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        subword_to_word_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "        \n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        sequence_output = self.dropout(outputs[1])\n",
        "        logits = []\n",
        "        for classifier in self.classifiers:\n",
        "            logit = classifier(sequence_output)\n",
        "            logits.append(logit)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            total_loss = 0\n",
        "            for i, (logit, num_label) in enumerate(zip(logits, self.num_labels)):\n",
        "                label = labels[:,i]\n",
        "                loss = loss_fct(logit.view(-1, num_label), label.view(-1))\n",
        "                total_loss += loss\n",
        "            outputs = (total_loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), scores, (hidden_states), (attentions)"
      ],
      "metadata": {
        "id": "ghzl4CeATup8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset"
      ],
      "metadata": {
        "id": "WHdEb9WkUnqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AspectBasedSentimentAnalysisDataset(Dataset):\n",
        "    # Static constant variable\n",
        "    ASPECT_DOMAIN = ['umum','layanan','menu','harga','fasilitas','suasana']\n",
        "    LABEL2INDEX = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "    INDEX2LABEL = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "    NUM_LABELS = [3, 3, 3, 3, 3, 3]\n",
        "    NUM_ASPECTS = 6\n",
        "    \n",
        "    def load_dataset(self, path):\n",
        "        df = pd.read_csv(path)\n",
        "        for aspect in self.ASPECT_DOMAIN:\n",
        "            df[aspect] = df[aspect].apply(lambda sen: self.LABEL2INDEX[sen])\n",
        "        return df\n",
        "    \n",
        "    def __init__(self, dataset_path, tokenizer, no_special_token=False, *args, **kwargs):\n",
        "        self.data = self.load_dataset(dataset_path)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.no_special_token = no_special_token\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        data = self.data.loc[index,:]\n",
        "        sentence, labels = data['review_text'], [data[aspect] for aspect in self.ASPECT_DOMAIN]\n",
        "        subwords = self.tokenizer.encode(sentence, add_special_tokens=not self.no_special_token)\n",
        "        return np.array(subwords), np.array(labels), data['review_text']\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "class AspectBasedSentimentAnalysisDataLoader(DataLoader):\n",
        "    def __init__(self, dataset, max_seq_len=512, *args, **kwargs):\n",
        "        super(AspectBasedSentimentAnalysisDataLoader, self).__init__(dataset=dataset, *args, **kwargs)\n",
        "        self.num_aspects = dataset.NUM_ASPECTS\n",
        "        self.collate_fn = self._collate_fn\n",
        "        self.max_seq_len = max_seq_len\n",
        "        \n",
        "    def _collate_fn(self, batch):\n",
        "        batch_size = len(batch)\n",
        "        max_seq_len = max(map(lambda x: len(x[0]), batch))\n",
        "        max_seq_len = min(self.max_seq_len, max_seq_len)\n",
        "        \n",
        "        subword_batch = np.zeros((batch_size, max_seq_len), dtype=np.int64)\n",
        "        mask_batch = np.zeros((batch_size, max_seq_len), dtype=np.float32)\n",
        "        label_batch = np.zeros((batch_size, self.num_aspects), dtype=np.int64)\n",
        "\n",
        "        seq_list = []\n",
        "        \n",
        "        for i, (subwords, label, raw_seq) in enumerate(batch):\n",
        "            subwords = subwords[:max_seq_len]\n",
        "            subword_batch[i,:len(subwords)] = subwords\n",
        "            mask_batch[i,:len(subwords)] = 1\n",
        "            label_batch[i,:] = label\n",
        "\n",
        "            seq_list.append(raw_seq)\n",
        "            \n",
        "        return subword_batch, mask_batch, label_batch, seq_list"
      ],
      "metadata": {
        "id": "7h3aGKJrM-zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ff"
      ],
      "metadata": {
        "id": "pz2mei6MUON9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward function for sequence multilabel classification\n",
        "def forward_sequence_multi_classification(model, batch_data, i2w, is_test=False, device='cpu', **kwargs): \n",
        "    # Unpack batch data\n",
        "    if len(batch_data) == 3:\n",
        "        (subword_batch, mask_batch, label_batch) = batch_data\n",
        "        token_type_batch = None\n",
        "    elif len(batch_data) == 4:\n",
        "        (subword_batch, mask_batch, token_type_batch, label_batch) = batch_data\n",
        "    \n",
        "    # Prepare input & label\n",
        "    subword_batch = torch.LongTensor(subword_batch)\n",
        "    mask_batch = torch.FloatTensor(mask_batch)\n",
        "    token_type_batch = torch.LongTensor(token_type_batch) if token_type_batch is not None else None\n",
        "    label_batch = torch.LongTensor(label_batch)\n",
        "            \n",
        "    if device == \"cuda\":\n",
        "        subword_batch = subword_batch.cuda()\n",
        "        mask_batch = mask_batch.cuda()\n",
        "        token_type_batch = token_type_batch.cuda() if token_type_batch is not None else None\n",
        "        label_batch = label_batch.cuda()\n",
        "\n",
        "    # Forward model\n",
        "    outputs = model(subword_batch, attention_mask=mask_batch, token_type_ids=token_type_batch, labels=label_batch)\n",
        "    loss, logits = outputs[:2] # logits list<tensor(bs, num_label)> ~ list of batch prediction per class \n",
        "    \n",
        "    # generate prediction & label list\n",
        "    list_hyp = []\n",
        "    list_label = []\n",
        "    hyp = [torch.topk(logit, 1)[1] for logit in logits] # list<tensor(bs)>\n",
        "    batch_size = label_batch.shape[0]\n",
        "    num_label = len(hyp)\n",
        "    for i in range(batch_size):\n",
        "        hyps = []\n",
        "        labels = label_batch[i,:].cpu().numpy().tolist()\n",
        "        for j in range(num_label):\n",
        "            hyps.append(hyp[j][i].item())\n",
        "        list_hyp.append([i2w[hyp] for hyp in hyps])\n",
        "        list_label.append([i2w[label] for label in labels])\n",
        "        \n",
        "    return loss, list_hyp, list_label"
      ],
      "metadata": {
        "id": "OAtdwsc-EKDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### saved data & model"
      ],
      "metadata": {
        "id": "a7R6v8kmT9Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Tokenizer, Config, Model\n",
        "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
        "config = BertConfig.from_pretrained('indobenchmark/indobert-base-p1')\n",
        "\n",
        "config.num_labels = max(AspectBasedSentimentAnalysisDataset.NUM_LABELS)\n",
        "config.num_labels_list = AspectBasedSentimentAnalysisDataset.NUM_LABELS\n",
        "model = BertForMultiLabelClassification.from_pretrained('indobenchmark/indobert-base-p1',config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXokWdY1TY6A",
        "outputId": "8af6e348-5215-49b5-ef61-3003c48c6ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForMultiLabelClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifiers.3.bias', 'classifiers.4.bias', 'classifiers.2.weight', 'classifiers.5.weight', 'classifiers.0.bias', 'classifiers.2.bias', 'classifiers.4.weight', 'classifiers.5.bias', 'classifiers.3.weight', 'classifiers.0.weight', 'classifiers.1.weight', 'classifiers.1.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('test_result_idbert.csv')\n",
        "\n",
        "state_dict = torch.load('model.pt')\n",
        "print(state_dict.keys())\n",
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "RSI2_aDULGp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "038387c2-3ecc-4141-86b0-ba97ef779917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['bert.embeddings.position_ids', 'bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifiers.0.weight', 'classifiers.0.bias', 'classifiers.1.weight', 'classifiers.1.bias', 'classifiers.2.weight', 'classifiers.2.bias', 'classifiers.3.weight', 'classifiers.3.bias', 'classifiers.4.weight', 'classifiers.4.bias', 'classifiers.5.weight', 'classifiers.5.bias'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn4ZTz1MGO8F",
        "outputId": "ff65a3b3-22e1-4d5f-a3fa-941309d5dcbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 385 entries, 0 to 384\n",
            "Data columns (total 22 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   Unnamed: 0           385 non-null    int64  \n",
            " 1   name                 385 non-null    object \n",
            " 2   location_link        385 non-null    object \n",
            " 3   reviews_link         385 non-null    object \n",
            " 4   reviews              385 non-null    int64  \n",
            " 5   rating               385 non-null    float64\n",
            " 6   review_text          385 non-null    object \n",
            " 7   review_link          385 non-null    object \n",
            " 8   review_rating        385 non-null    int64  \n",
            " 9   review_datetime_utc  385 non-null    object \n",
            " 10  umum                 385 non-null    object \n",
            " 11  layanan              385 non-null    object \n",
            " 12  menu                 385 non-null    object \n",
            " 13  harga                385 non-null    object \n",
            " 14  fasilitas            385 non-null    object \n",
            " 15  suasana              385 non-null    object \n",
            " 16  pred_umum            385 non-null    object \n",
            " 17  pred_layanan         385 non-null    object \n",
            " 18  pred_menu            385 non-null    object \n",
            " 19  pred_harga           385 non-null    object \n",
            " 20  pred_fasilitas       385 non-null    object \n",
            " 21  pred_suasana         385 non-null    object \n",
            "dtypes: float64(1), int64(3), object(18)\n",
            "memory usage: 66.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2i, i2w = AspectBasedSentimentAnalysisDataset.LABEL2INDEX, AspectBasedSentimentAnalysisDataset.INDEX2LABEL\n",
        "print(w2i)\n",
        "print(i2w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbPUeqD989gb",
        "outputId": "c4848a03-1ae8-4111-caf4-76bb49120566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'negative': 0, 'neutral': 1, 'positive': 2}\n",
            "{0: 'negative', 1: 'neutral', 2: 'positive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dashboard"
      ],
      "metadata": {
        "id": "vB1GV5duUGNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stylesheet \n",
        "dbc_css = \"https://cdn.jsdelivr.net/gh/AnnMarieW/dash-bootstrap-templates/dbc.min.css\"\n",
        "\n",
        "# Define app\n",
        "app = JupyterDash(__name__, external_stylesheets=[dbc.themes.FLATLY, dbc_css])\n",
        "server = app.server\n",
        "\n",
        "# Define the layout of the app\n",
        "# app.layout = html.Div([  \n",
        "# Title\n",
        "header = html.H3('Aspect-based Sentiment Analysis Dashboard', className=\"bg-primary text-white p-2 mb-2 text-center\")\n",
        "html.Br()\n",
        "\n",
        "# Dropdown menu for selecting the cafe name\n",
        "dropdown = html.Div(\n",
        "            [\n",
        "                dbc.Label(\"Select cafe and coworking space\"),\n",
        "                dcc.Dropdown(\n",
        "                id='cafe-dropdown',\n",
        "                options=[{'label': name, 'value': name} for name in df['name'].unique()],\n",
        "                value=df['name'].iloc[0]\n",
        "                )\n",
        "            ], className=\"mb-4\",\n",
        "            )\n",
        "    \n",
        "  \n",
        "# Graph for showing the sentiment polarity\n",
        "graph1 = html.Div([\n",
        "              dcc.Graph(id='polarity-graph')\n",
        "          ])\n",
        "\n",
        "# Graph for showing the aspect-based sentiment analysis\n",
        "graph2 = html.Div([\n",
        "              dcc.Graph(id='sentiment-graph')\n",
        "          ])\n",
        "\n",
        "# Text field and button for predicting new review\n",
        "review = html.Div([\n",
        "            html.Label('Try a new review'),\n",
        "            dcc.Input(\n",
        "                id='new-review-input',\n",
        "                type='text',\n",
        "                placeholder='Type your review here...',\n",
        "                style={'width': '100%', 'display': 'inline-block'}\n",
        "            ),\n",
        "            html.Br(),\n",
        "            dbc.Button('Submit', id='new-review-button', color='primary', className='mt-2'),\n",
        "            html.Br(),\n",
        "            html.Div(id='new-review-output')\n",
        "        ], style={'width': '100%', 'display': 'inline-block', 'vertical-align': 'top', 'margin-top': '20px', 'margin-bottom': '50px'})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "theme_colors = [\n",
        "    \"primary\",\n",
        "    \"secondary\",\n",
        "    \"success\",\n",
        "    \"warning\",\n",
        "    \"danger\",\n",
        "    \"info\",\n",
        "    \"light\",\n",
        "    \"dark\",\n",
        "    \"link\",\n",
        "]\n",
        "\n",
        "colors = html.Div(\n",
        "    [dbc.Button(f\"{color}\", color=f\"{color}\", size=\"sm\") for color in theme_colors]\n",
        ")\n",
        "colors = html.Div([\"Theme Colors:\", colors], className=\"mt-2\")\n",
        "\n",
        "# ])\n",
        "tab1 = dbc.Tab([graph2], label=\"Aspect-Sentiment Graph\")\n",
        "tab2 = dbc.Tab([graph1], label=\"Overall Chart\")\n",
        "# # tab3 = dbc.Tab([table], label=\"Table\", className=\"p-4\")\n",
        "tabs = dbc.Card(dbc.Tabs([tab1, tab2]))\n",
        "\n",
        "card1 = dbc.Card(\n",
        "    [dropdown, tabs],\n",
        "    body=True,\n",
        ")\n",
        "card2 = dbc.Card(\n",
        "    [review],\n",
        "    body=True,\n",
        ")\n",
        "\n",
        "app.layout = dbc.Container(\n",
        "    [\n",
        "        header,\n",
        "        dbc.Row(\n",
        "            [\n",
        "                dbc.Col(\n",
        "                    [\n",
        "                        card1,\n",
        "                        # ThemeChangerAIO(aio_id=\"theme\")\n",
        "                    ],\n",
        "                    width=8,\n",
        "                ),\n",
        "                dbc.Col([card2], width=4),\n",
        "            ]\n",
        "        ),\n",
        "    ],\n",
        "    fluid=True,\n",
        "    className=\"dbc\",\n",
        ")"
      ],
      "metadata": {
        "id": "-nBceOGn4NRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the callback function to update the polarity graph\n",
        "@app.callback(\n",
        "    Output('polarity-graph', 'figure'),\n",
        "    Input('cafe-dropdown', 'value')\n",
        ")\n",
        "\n",
        "def update_polarity_graph(selected_cafe):\n",
        "    filtered_df = df[df['name'] == selected_cafe]\n",
        "    sentiment_counts = filtered_df[['pred_umum', 'pred_layanan', 'pred_menu', 'pred_harga', 'pred_fasilitas', 'pred_suasana']].stack().value_counts()\n",
        "    color_dict = {'positive': '#00CC96', 'negative': '#EF553B', 'neutral': '#636EFA'}\n",
        "    colors = [color_dict[sentiment] for sentiment in sentiment_counts.index]\n",
        "\n",
        "    polarity_fig = px.pie(\n",
        "        values=sentiment_counts.values,\n",
        "        names=sentiment_counts.index,\n",
        "        title='Overall Sentiment Polarity Distribution for {}'.format(selected_cafe),\n",
        "        color_discrete_sequence=colors\n",
        "\n",
        "    )\n",
        "    return polarity_fig\n",
        "\n",
        "# def update_polarity_graph(selected_cafe):\n",
        "#     filtered_df = df[df['name'] == selected_cafe]\n",
        "#     polarity_counts = filtered_df['pred_umum'].value_counts(normalize=True)\n",
        "#     polarity_fig = px.pie(\n",
        "#         values=polarity_counts.values,\n",
        "#         names=polarity_counts.index,\n",
        "#         title='General Sentiment Polarity Distribution for {}'.format(selected_cafe),\n",
        "#         color_discrete_sequence=['#00CC96', '#EF553B', '#636EFA'] \n",
        "#     )\n",
        "#     return polarity_fig\n",
        "\n",
        "\n",
        "# Define the callback function to update the aspect-based sentiment analysis graph\n",
        "@app.callback(\n",
        "    Output('sentiment-graph', 'figure'),\n",
        "    Input('cafe-dropdown', 'value')\n",
        ")\n",
        "\n",
        "def update_sentiment_graph(selected_cafe):\n",
        "    filtered_df = df[df['name'] == selected_cafe]\n",
        "    aspect_scores = filtered_df.melt(id_vars=['name'], value_vars=['pred_umum','pred_layanan', 'pred_menu', 'pred_harga', 'pred_fasilitas', 'pred_suasana'], var_name='aspect', value_name='score')\n",
        "    aspect_scores['aspect'] = aspect_scores['aspect'].apply(lambda x: x[5:].capitalize() if x.startswith('pred_') else x) # capitalize aspect names and remove 'pred_' prefix\n",
        "\n",
        "    aspect_counts = aspect_scores.groupby(['aspect', 'score']).size().reset_index(name='count')\n",
        "    aspect_order = ['Umum', 'Layanan', 'Menu', 'Harga', 'Fasilitas', 'Suasana']\n",
        "    aspect_counts['aspect'] = pd.Categorical(aspect_counts['aspect'], categories=aspect_order, ordered=True)\n",
        "    aspect_counts = aspect_counts.sort_values('aspect')\n",
        "\n",
        "    fig = go.Figure()\n",
        "    for sentiment, color in zip(['positive','negative','neutral'],['#00CC96','#EF553B','#636EFA']):\n",
        "        sentiment_counts = aspect_counts[aspect_counts['score'] == sentiment]\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=sentiment_counts['aspect'],\n",
        "            y=sentiment_counts['count'],\n",
        "            name=sentiment,\n",
        "            marker_color=color # set the color for the current sentiment\n",
        "\n",
        "        ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title='Aspect-Based Sentiment Analysis for {}'.format(selected_cafe),\n",
        "        xaxis_title='Aspect',\n",
        "        yaxis_title='Number of Reviews',\n",
        "        barmode='group'\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "# Define the callback function to predict aspect-based sentiment analysis for a new review\n",
        "@app.callback(\n",
        "    Output('new-review-output', 'children'),\n",
        "    Input('new-review-button', 'n_clicks'),\n",
        "    State('new-review-input', 'value')\n",
        ")\n",
        "def predict_new_review_sentiment_analysis(n_clicks, value):\n",
        "    if n_clicks is None:\n",
        "        return ''\n",
        "    if not value:\n",
        "        return ''\n",
        "    \n",
        "    subwords = tokenizer.encode(value)\n",
        "    subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "    logits = model(subwords)[0]\n",
        "    labels = [torch.topk(logit, k=1, dim=-1)[1].squeeze().item() for logit in logits]\n",
        "    \n",
        "    output = []\n",
        "    output.append(html.Label('sentimen umum: {}'.format(i2w[labels[0]])))\n",
        "    output.append(html.Br())\n",
        "    for i in range(1, len(labels)):\n",
        "        output.append(html.Label('aspek {}: {}'.format(AspectBasedSentimentAnalysisDataset.ASPECT_DOMAIN[i], i2w[labels[i]])))\n",
        "        output.append(html.Br())\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "app.run_server(mode='external')"
      ],
      "metadata": {
        "id": "d4ZmRLb9G4Au",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "23cd1cf9-3544-450d-f561-9a7fbf046e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dash is running on http://127.0.0.1:8050/\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:dash.dash:Dash is running on http://127.0.0.1:8050/\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dash app running on:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8050, \"/\", \"http://127.0.0.1:8050/\", window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyngrok import ngrok\n",
        "\n",
        "# public_url = ngrok.connect(port='8050')\n",
        "# print(f'Open this URL in your browser: {public_url}')"
      ],
      "metadata": {
        "id": "Y6Yawaai8izA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ngrok.disconnect(public_url)"
      ],
      "metadata": {
        "id": "k-uk5-6U-uAr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}