{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Yotaa2wobLYy",
        "_3fZeDSWA917",
        "vAA9br4DM8BB",
        "0yKv7pcPGaSs",
        "TkyNlazzbR4w",
        "LMmc8tvuQQUd",
        "DMU2M-PXLH8X",
        "UV3-FhLbT7Dv",
        "g6vHYV3jrxLx",
        "F6y9Gzc8UAns",
        "g-hs8phD_DkW",
        "dRr76LEs-_2q",
        "EJxdUEebBqzO",
        "qB_T7LOzC3uN",
        "c3FvVOQpDaQ_",
        "rshihYgwD2ax",
        "S3YmPw6wEFrR",
        "KLmDLSl-EIkI",
        "V2m8DTjtFCGP",
        "75jb3TaeFNpD"
      ],
      "authorship_tag": "ABX9TyN7xyr5jn28l9JuWet3iLpG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salsabillaflsft/ABSApublic/blob/main/theinnerworkings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transformers - BERT - IndoBERT : inner workings**"
      ],
      "metadata": {
        "id": "FNMPyl7WOLXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "Yotaa2wobLYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq_aTJ6804A8",
        "outputId": "fc9973b5-48a5-4e08-c9ef-6cdab808723b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tqdm import tqdm\n",
        "from transformers import (BertTokenizer, BertConfig, BertForPreTraining, BertPreTrainedModel, \n",
        "                          apply_chunking_to_forward, BertModel, set_seed)\n",
        "from transformers.activations import gelu\n",
        "from transformers.modeling_outputs import (BaseModelOutputWithPastAndCrossAttentions, \n",
        "                                           BaseModelOutputWithPoolingAndCrossAttentions, \n",
        "                                           SequenceClassifierOutput)\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
      ],
      "metadata": {
        "id": "oj8Zx0ZfbA45"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility.\n",
        "set_seed(123)\n",
        "\n",
        "# How many labels are we using in training.\n",
        "# This is used to decide size of classification head.\n",
        "n_labels = 3\n",
        "\n",
        "# GELU Activation function.\n",
        "ACT2FN = {\"gelu\": gelu}\n",
        "\n",
        "# Define BertLayerNorm.\n",
        "BertLayerNorm = torch.nn.LayerNorm"
      ],
      "metadata": {
        "id": "53ZQoLg5ADvq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3fZeDSWA917"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset "
      ],
      "metadata": {
        "id": "vAA9br4DM8BB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "u_Th-A2MA_kX"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# %cd /content/drive/My Drive/TA/Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_folder_path = '/content/drive/MyDrive//TA/Dataset'"
      ],
      "metadata": {
        "id": "BPISE7QNO0ON"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset_path = dataset_folder_path + '/train_preprocess_70.csv'\n",
        "# valid_dataset_path = dataset_folder_path + '/val_preprocess_15.csv'\n",
        "# test_dataset_path = dataset_folder_path + '/test_preprocess_15.csv'"
      ],
      "metadata": {
        "id": "_NfiomXKPFGS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example 11-3-4-5-6\n",
        "data = [\n",
        "    \"Tempatnya asyik utk nyantai bareng teman2 ,  walau gang masuk nya sempit .  Mobil parkir di jalan besar .\",\n",
        "    \"Tempatnya enak ,  menunya enak tp pegawainya kok songong yaa .  Kapok sih ,  ga bakalan ke sana lagi\",\n",
        "    \"Tempat nongkrong jaman maba banget nyaman sih buat nugas\",\n",
        "    \"Agak panas dan tumben penuh padahal siang2 kesana\",\n",
        "    \"Cocok kalo untuk kerja atau nugas\",\n",
        "]\n",
        "\n",
        "# labels = [\"positive,\tneutral,\tneutral,\tneutral,\tneutral,\tpositive\",\n",
        "#           \"negative,\tnegative,\tpositive,\tneutral,\tneutral,\tpositive\",\n",
        "#           \"positive,\tneutral,\tneutral,\tneutral,\tneutral,\tpositive\",\n",
        "#           \"positive,\tneutral,\tneutral,\tneutral,\tnegative,\tneutral\",\n",
        "#           \"positive,\tneutral,\tneutral,\tneutral,\tneutral,\tpositive\",\n",
        "#           ]\n",
        "\n",
        "aspects = ['umum','layanan','menu','harga','fasilitas','suasana']\n",
        "\n",
        "labels = [[2,\t1,\t1,\t1,\t1,\t2],\n",
        "          [0,\t0,\t2,\t1,\t1,\t2],\n",
        "          [2,\t1,\t1,\t1,\t1,\t2],\n",
        "          [2,\t1,\t1,\t1,\t0,\t1],\n",
        "          [2,\t1,\t1,\t1,\t1,\t2],\n",
        "          ]"
      ],
      "metadata": {
        "id": "_yBTKF_qL9Ll"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modules (dataset)"
      ],
      "metadata": {
        "id": "0yKv7pcPGaSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AspectBasedSentimentAnalysisDataset(Dataset):\n",
        "    # Static constant variable\n",
        "    ASPECT_DOMAIN = ['umum','layanan','menu','harga','fasilitas','suasana']\n",
        "    LABEL2INDEX = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "    INDEX2LABEL = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "    NUM_LABELS = [3, 3, 3, 3, 3, 3]\n",
        "    NUM_ASPECTS = 6\n",
        "    \n",
        "    def load_dataset(self, path):\n",
        "        df = pd.read_csv(path)\n",
        "        for aspect in self.ASPECT_DOMAIN:\n",
        "            df[aspect] = df[aspect].apply(lambda sen: self.LABEL2INDEX[sen])\n",
        "        return df\n",
        "    \n",
        "    def __init__(self, dataset_path, tokenizer, no_special_token=False, *args, **kwargs):\n",
        "        self.data = self.load_dataset(dataset_path)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.no_special_token = no_special_token\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        data = self.data.loc[index,:]\n",
        "        sentence, labels = data['review_text'], [data[aspect] for aspect in self.ASPECT_DOMAIN]\n",
        "        subwords = self.tokenizer.encode(sentence, add_special_tokens=not self.no_special_token)\n",
        "        return np.array(subwords), np.array(labels), data['review_text']\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "class AspectBasedSentimentAnalysisDataLoader(DataLoader):\n",
        "    def __init__(self, dataset, max_seq_len=512, *args, **kwargs):\n",
        "        super(AspectBasedSentimentAnalysisDataLoader, self).__init__(dataset=dataset, *args, **kwargs)\n",
        "        self.num_aspects = dataset.NUM_ASPECTS\n",
        "        self.collate_fn = self._collate_fn\n",
        "        self.max_seq_len = max_seq_len\n",
        "        \n",
        "    def _collate_fn(self, batch):\n",
        "        batch_size = len(batch)\n",
        "        max_seq_len = max(map(lambda x: len(x[0]), batch))\n",
        "        max_seq_len = min(self.max_seq_len, max_seq_len)\n",
        "        \n",
        "        subword_batch = np.zeros((batch_size, max_seq_len), dtype=np.int64)\n",
        "        mask_batch = np.zeros((batch_size, max_seq_len), dtype=np.float32)\n",
        "        label_batch = np.zeros((batch_size, self.num_aspects), dtype=np.int64)\n",
        "\n",
        "        seq_list = []\n",
        "        \n",
        "        for i, (subwords, label, raw_seq) in enumerate(batch):\n",
        "            subwords = subwords[:max_seq_len]\n",
        "            subword_batch[i,:len(subwords)] = subwords\n",
        "            mask_batch[i,:len(subwords)] = 1\n",
        "            label_batch[i,:] = label\n",
        "\n",
        "            seq_list.append(raw_seq)\n",
        "            \n",
        "        return subword_batch, mask_batch, label_batch, seq_list"
      ],
      "metadata": {
        "id": "7h3aGKJrM-zA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1MlUQa7FnAt"
      },
      "source": [
        "MultiLabel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForMultiLabelClassification(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels_list\n",
        "\n",
        "        self.bert = BertModel(config)  #bert model layer\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)  #bert dropout layer\n",
        "        self.classifiers = nn.ModuleList([nn.Linear(config.hidden_size, num_label) for num_label in self.num_labels]) #bert classification layer\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        subword_to_word_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        sequence_output = self.dropout(outputs[1])\n",
        "        logits = []\n",
        "        for classifier in self.classifiers:\n",
        "            logit = classifier(sequence_output)\n",
        "            logits.append(logit)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            total_loss = 0\n",
        "            for i, (logit, num_label) in enumerate(zip(logits, self.num_labels)):\n",
        "                label = labels[:,i]\n",
        "                loss = loss_fct(logit.view(-1, num_label), label.view(-1))\n",
        "                total_loss += loss\n",
        "            outputs = (total_loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), scores, (hidden_states), (attentions)"
      ],
      "metadata": {
        "id": "ihkSdo8PcDPj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model, Tokenizer, Config"
      ],
      "metadata": {
        "id": "TkyNlazzbR4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Tokenizer, Config, Model\n",
        "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
        "config = BertConfig.from_pretrained('indobenchmark/indobert-base-p1')\n",
        "\n",
        "config.num_labels = max(AspectBasedSentimentAnalysisDataset.NUM_LABELS)\n",
        "config.num_labels_list = AspectBasedSentimentAnalysisDataset.NUM_LABELS\n",
        "model = BertForMultiLabelClassification.from_pretrained('indobenchmark/indobert-base-p1',config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERqTWnaPbQoL",
        "outputId": "7132a9d2-1ea7-458d-c15b-58f616e96d93"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForMultiLabelClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifiers.5.weight', 'classifiers.3.bias', 'classifiers.1.bias', 'classifiers.2.bias', 'classifiers.0.bias', 'classifiers.0.weight', 'classifiers.2.weight', 'classifiers.4.bias', 'classifiers.3.weight', 'classifiers.5.bias', 'classifiers.1.weight', 'classifiers.4.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('NUMBER OF LAYERS:', config.num_hidden_layers)\n",
        "\n",
        "print('EMBEDDING SIZE:', config.hidden_size)\n",
        "\n",
        "print('ACTIVATIONS:', config.hidden_act)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnosv-bJR8Ww",
        "outputId": "7ef2c6c0-1a78-4573-ec03-6aad0f7b9fbb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUMBER OF LAYERS: 12\n",
            "EMBEDDING SIZE: 768\n",
            "ACTIVATIONS: gelu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0dZr2USJl6m",
        "outputId": "593dbbbc-7a25-4e86-aba5-7cdd6e2081e8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMultiLabelClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifiers): ModuleList(\n",
              "    (0-5): 6 x Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset = AspectBasedSentimentAnalysisDataset(train_dataset_path, tokenizer, lowercase=True)\n",
        "# valid_dataset = AspectBasedSentimentAnalysisDataset(valid_dataset_path, tokenizer, lowercase=True)\n",
        "# test_dataset = AspectBasedSentimentAnalysisDataset(test_dataset_path, tokenizer, lowercase=True)"
      ],
      "metadata": {
        "id": "XMi0kG0ePP_Y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loader = AspectBasedSentimentAnalysisDataLoader(dataset=train_dataset, max_seq_len=512, batch_size=16, num_workers=2, shuffle=True)  \n",
        "# valid_loader = AspectBasedSentimentAnalysisDataLoader(dataset=valid_dataset, max_seq_len=512, batch_size=16, num_workers=2, shuffle=False)  \n",
        "# test_loader = AspectBasedSentimentAnalysisDataLoader(dataset=test_dataset, max_seq_len=512, batch_size=16, num_workers=2, shuffle=False)"
      ],
      "metadata": {
        "id": "cebzNZKNP0Ib"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Processing - Tokenizer - WordPiece"
      ],
      "metadata": {
        "id": "LMmc8tvuQQUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenization, token to ids, special tokens, label *encoding*, padding truncating, att masks"
      ],
      "metadata": {
        "id": "RIQKdOFHl7A1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mviia1-nn-nv"
      },
      "source": [
        "WordPiece tokenization - the inner workings -> [wordpiece inner workings](https://colab.research.google.com/drive/1LYVJDlsFje9DNUvpS1gQybpbN9j7NrHb?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = tokenizer(text=data, add_special_tokens=True, padding=True, truncation=True, return_tensors='pt')\n",
        "input_sequences.update({'labels':torch.tensor(labels)})\n",
        "\n",
        "[print('%s : %s\\n'%(k,v)) for k,v in input_sequences.items()];"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJz6v2X6LWNd",
        "outputId": "acfb5b05-4262-42cc-f2f6-1c07a97ccb15"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids : tensor([[    2,  7229,  8181,  4302,  1107, 12006,    94,  8074,  1614, 30378,\n",
            "         30468,  1766, 10357,   804,  1107,  7132, 30470,   895,  5222,    26,\n",
            "           795,   421, 30470,     3,     0],\n",
            "        [    2,  7229,  3107, 30468,  1622,    57,  3107,  3478,  3027,    57,\n",
            "          2105, 30052,  2692,  5633, 30470,  1012,   118,  1966, 30468,   525,\n",
            "         10263,    43,  2377,   423,     3],\n",
            "        [    2,   515, 16503,  4881,  6943, 30354,  2174,  2382,  1966,   968,\n",
            "         19287,    22,     3,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0],\n",
            "        [    2,  2839,  1990,    41,  1349,  1771,  1876,  2234,  3346, 30378,\n",
            "         11105,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0],\n",
            "        [    2,  2040,  1686,    90,   494,   158, 19287,    22,     3,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0]])\n",
            "\n",
            "token_type_ids : tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0]])\n",
            "\n",
            "attention_mask : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0]])\n",
            "\n",
            "labels : tensor([[2, 1, 1, 1, 1, 2],\n",
            "        [0, 0, 2, 1, 1, 2],\n",
            "        [2, 1, 1, 1, 1, 2],\n",
            "        [2, 1, 1, 1, 0, 1],\n",
            "        [2, 1, 1, 1, 1, 2]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[print(tokenizer.decode(example)) for example in input_sequences['input_ids'].numpy()];"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtx096ShRjG9",
        "outputId": "a05bccb9-38ca-4f11-97ff-687725223a23"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] tempatnya asyik utk nyantai bareng teman2, walau gang masuk nya sempit. mobil parkir di jalan besar. [SEP] [PAD]\n",
            "[CLS] tempatnya enak, menunya enak tp pegawainya kok songong yaa. kapok sih, ga bakalan ke sana lagi [SEP]\n",
            "[CLS] tempat nongkrong jaman maba banget nyaman sih buat nugas [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] agak panas dan tumben penuh padahal siang2 kesana [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] cocok kalo untuk kerja atau nugas [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### result based on all data"
      ],
      "metadata": {
        "id": "DMU2M-PXLH8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # example on pre-processing based on all data\n",
        "# train_dataset[9]"
      ],
      "metadata": {
        "id": "coS4v5BnfrgT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Get an iterator for the train_loader\n",
        "# train_iter = iter(train_loader)\n",
        "\n",
        "# # Get the first batch of data\n",
        "# batch_data = next(train_iter)"
      ],
      "metadata": {
        "id": "6Gc6-brIl8cA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_data # this shows the token to ids(padded to same length, special tokens added), attention masks, label(encoded), the data)"
      ],
      "metadata": {
        "id": "gySKF7t5J6hm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Embedding: Token - Segment - Position"
      ],
      "metadata": {
        "id": "UV3-FhLbT7Dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class Embeddings(nn.Module):\n",
        "#     def __init__(self, d_model, vocab):\n",
        "#         super(Embeddings, self).__init__()\n",
        "#         self.lut = nn.Embedding(vocab, d_model)\n",
        "#         self.d_model = d_model\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.lut(x) * math.sqrt(self.d_model)"
      ],
      "metadata": {
        "id": "XagBlf4p2a-0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PE"
      ],
      "metadata": {
        "id": "_NDKn_w4V2WP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "positional encoding/embedding\n",
        "- transformer takes all the embedding at once\n",
        "- filling with the words order will distort the infos\n",
        "- added normalization will confuse the model\n",
        "\n",
        "PE -> used frequencies to capture data infos\n"
      ],
      "metadata": {
        "id": "dPcqnn8aUelO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PE(ð‘ð‘œð‘ ,2ð‘–)=ð‘ ð‘–ð‘›(ð‘ð‘œð‘ /(10000^2ð‘–/ð‘‘ð‘šð‘œð‘‘ð‘’ð‘™))\n",
        " \n",
        "PE(ð‘ð‘œð‘ ,2ð‘–+1)=ð‘ð‘œð‘ (ð‘ð‘œð‘ /(10000^2ð‘–/ð‘‘ð‘šð‘œð‘‘ð‘’ð‘™))\n",
        "\n",
        "pos = position of the word (max sequence length = 512)(in this, length of tokens = 25)\n",
        "\n",
        "i = indices, dimensions of the embedding (768)\n",
        "\n",
        "dmodel = dimension/size of the embedding \n",
        "(BERT embedding size -> 768) \n",
        "\n",
        "with this formulas/calculation, each word with diff positions will have different position embeddings values\n"
      ],
      "metadata": {
        "id": "I5k6irEcVvtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class PositionalEncoding(nn.Module):\n",
        "#     \"Implement the PE function.\"\n",
        "\n",
        "#     def __init__(self, d_model, dropout, max_len=5000):\n",
        "#         super(PositionalEncoding, self).__init__()\n",
        "#         self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "#         # Compute the positional encodings once in log space.\n",
        "#         pe = torch.zeros(max_len, d_model)\n",
        "#         position = torch.arange(0, max_len).unsqueeze(1)\n",
        "#         div_term = torch.exp(\n",
        "#             torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
        "#         )\n",
        "#         pe[:, 0::2] = torch.sin(position * div_term)\n",
        "#         pe[:, 1::2] = torch.cos(position * div_term)\n",
        "#         pe = pe.unsqueeze(0)\n",
        "#         self.register_buffer(\"pe\", pe)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
        "#         return self.dropout(x)"
      ],
      "metadata": {
        "id": "AtaFF72i2bcY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def show_example(fn, args=[]):\n",
        "#     if __name__ == \"__main__\":\n",
        "#         return fn(*args)\n",
        "\n",
        "# def example_positional():\n",
        "#     pe = PositionalEncoding(20, 0)\n",
        "#     y = pe.forward(torch.zeros(1, 100, 20))\n",
        "\n",
        "#     data = pd.concat(\n",
        "#         [\n",
        "#             pd.DataFrame(\n",
        "#                 {\n",
        "#                     \"embedding\": y[0, :, dim],\n",
        "#                     \"dimension\": dim,\n",
        "#                     \"position\": list(range(100)),\n",
        "#                 }\n",
        "#             )\n",
        "#             for dim in [4, 5, 6, 7]\n",
        "#         ]\n",
        "#     )\n",
        "\n",
        "#     return (\n",
        "#         alt.Chart(data)\n",
        "#         .mark_line()\n",
        "#         .properties(width=800)\n",
        "#         .encode(x=\"position\", y=\"embedding\", color=\"dimension:N\")\n",
        "#         .interactive()\n",
        "#     )\n",
        "\n",
        "\n",
        "# show_example(example_positional)"
      ],
      "metadata": {
        "id": "BG-VavEX2mMa"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #for pos embedding visualizations, include pos encoding formulas\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# def pos_visualize(position_embeddings):\n",
        "#     # Extract the shape of the position embeddings.\n",
        "#     _, pos, d_model = position_embeddings.shape #[1,25,78]\n",
        "    \n",
        "#     even_i = np.arange(0, d_model, 2, dtype='int')\n",
        "#     odd_i = np.arange(1, d_model, 2, dtype='int')\n",
        "#     pe_1 = []\n",
        "#     pe_2 = []\n",
        "\n",
        "#     for _pos in range(pos):\n",
        "#         pe_even = np.sin(_pos / np.power(10000, (2 * even_i / d_model)))\n",
        "#         pe_odd = np.cos(_pos / np.power(10000, (2 * odd_i / d_model)))\n",
        "#         pe_1.append(np.insert(pe_even, list(range(1, len(pe_odd) + 1)), pe_odd))\n",
        "#         pe_2.append(np.concatenate([pe_even, pe_odd]))\n",
        "\n",
        "#     # Create heatmaps to visualize the positional embeddings.\n",
        "#     plt.figure(figsize=(10, 5))\n",
        "#     plt.subplot(1, 2, 1)\n",
        "#     sns.heatmap(pe_1, cmap='GnBu')\n",
        "#     plt.title('Sine Positional Embeddings')\n",
        "#     plt.xlabel('Embedding Dimension')\n",
        "#     plt.ylabel('Position')\n",
        "#     plt.subplot(1, 2, 2)\n",
        "#     sns.heatmap(pe_2, cmap='GnBu')\n",
        "#     plt.title('Cosine Positional Embeddings')\n",
        "#     plt.xlabel('Embedding Dimension')\n",
        "#     plt.ylabel('Position')\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "TzCjrDxAnyTv"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def pos_visualize(position_embeddings):\n",
        "    # Extract the shape of the position embeddings.\n",
        "    _, pos, d_model = position_embeddings.shape \n",
        "    \n",
        "    # Compute the positional encodings.\n",
        "    pe = np.zeros((pos, d_model))\n",
        "    for pos_idx in range(pos):\n",
        "        for i in range(0, d_model, 2):\n",
        "            pe[pos_idx, i] = np.sin(pos_idx / (10000 ** ((2*i) / d_model)))\n",
        "            pe[pos_idx, i+1] = np.cos(pos_idx / (10000 ** ((2*i+1) / d_model)))\n",
        "    \n",
        "    # Plot the positional encodings.\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.heatmap(pe, cmap='GnBu')\n",
        "    plt.title('Positional Embeddings')\n",
        "    plt.xlabel('Embedding Dimension')\n",
        "    plt.ylabel('Position')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Pa8FixmI0Uhy"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "g6vHYV3jrxLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertEmbeddings(torch.nn.Module):\n",
        "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.word_embeddings = torch.nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
        "        self.position_embeddings = torch.nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "        self.token_type_embeddings = torch.nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
        "\n",
        "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load any TensorFlow checkpoint file\n",
        "        self.LayerNorm = torch.nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # position_ids (1, len position emb) is contiguous in memory and exported when serialized\n",
        "        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))\n",
        "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
        "\n",
        "    def forward(\n",
        "        self, input_ids=None, token_type_ids=None, position_ids=None, inputs_embeds=None, past_key_values_length=0\n",
        "    ):\n",
        "        if input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        else:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "\n",
        "        seq_length = input_shape[1]\n",
        "\n",
        "        if position_ids is None:\n",
        "            position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]\n",
        "\n",
        "        print('Created Tokens Positions IDs:\\n', position_ids)        \n",
        "\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.word_embeddings(input_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "\n",
        "        # Inputs IDS\n",
        "        print('\\nTokens IDs shape:\\n', input_ids.shape)\n",
        "        print('\\nTokens IDs:\\n', input_ids)\n",
        "        # Segment Embedding\n",
        "        print('\\nTokens Type IDs shape:\\n', token_type_ids.shape)\n",
        "        print('\\nTokens Type IDs / Segments:\\n', token_type_ids)\n",
        "        # Token Embedding\n",
        "        print('\\nWord Embeddings shape:\\n', inputs_embeds.shape)\n",
        "        print('\\nWord Embeddings #1:\\n', inputs_embeds)\n",
        "\n",
        "\n",
        "        embeddings = inputs_embeds + token_type_embeddings\n",
        "        if self.position_embedding_type == \"absolute\":\n",
        "            position_embeddings = self.position_embeddings(position_ids)\n",
        "\n",
        "            # Position Embedding\n",
        "            print('\\nPosition Embeddings:\\n', position_embeddings.shape)\n",
        "            print('\\nPosition Embeddings:\\n', position_embeddings)\n",
        "            embeddings += position_embeddings\n",
        "            pos_visualize(position_embeddings)\n",
        "\n",
        "        print('\\nToken Types Embeddings:\\n', token_type_embeddings.shape)\n",
        "        print('\\nToken Types Embeddings:\\n', token_type_embeddings)\n",
        "        \n",
        "        print('\\nSum Up All Embeddings:\\n', embeddings.shape)\n",
        "        print('\\nResult:\\n', embeddings)\n",
        "\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "\n",
        "        print('\\nEmbeddings Layer Normalization:\\n', embeddings.shape)\n",
        "\n",
        "        embeddings = self.dropout(embeddings)\n",
        "\n",
        "        print('\\nEmbeddings Dropout Layer:\\n', embeddings.shape)\n",
        "        \n",
        "        return embeddings\n",
        "\n",
        "\n",
        "# Create Bert embedding layer.\n",
        "bert_embeddings_block = BertEmbeddings(config)\n",
        "\n",
        "# Perform a forward pass.\n",
        "embedding_output = bert_embeddings_block.forward(input_ids=input_sequences['input_ids'], token_type_ids=input_sequences['token_type_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DCb-87Cqnq1N",
        "outputId": "5735a32e-9d31-403a-b7f2-156ef89ca13f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created Tokens Positions IDs:\n",
            " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "         18, 19, 20, 21, 22, 23, 24]])\n",
            "\n",
            "Tokens IDs shape:\n",
            " torch.Size([5, 25])\n",
            "\n",
            "Tokens IDs:\n",
            " tensor([[    2,  7229,  8181,  4302,  1107, 12006,    94,  8074,  1614, 30378,\n",
            "         30468,  1766, 10357,   804,  1107,  7132, 30470,   895,  5222,    26,\n",
            "           795,   421, 30470,     3,     0],\n",
            "        [    2,  7229,  3107, 30468,  1622,    57,  3107,  3478,  3027,    57,\n",
            "          2105, 30052,  2692,  5633, 30470,  1012,   118,  1966, 30468,   525,\n",
            "         10263,    43,  2377,   423,     3],\n",
            "        [    2,   515, 16503,  4881,  6943, 30354,  2174,  2382,  1966,   968,\n",
            "         19287,    22,     3,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0],\n",
            "        [    2,  2839,  1990,    41,  1349,  1771,  1876,  2234,  3346, 30378,\n",
            "         11105,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0],\n",
            "        [    2,  2040,  1686,    90,   494,   158, 19287,    22,     3,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0]])\n",
            "\n",
            "Tokens Type IDs shape:\n",
            " torch.Size([5, 25])\n",
            "\n",
            "Tokens Type IDs / Segments:\n",
            " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0]])\n",
            "\n",
            "Word Embeddings shape:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Word Embeddings #1:\n",
            " tensor([[[ 1.7867e+00, -2.8281e-01,  7.1723e-01,  ..., -6.4661e-01,\n",
            "           2.7737e+00, -1.2397e+00],\n",
            "         [ 1.1810e-01, -8.0549e-01, -6.7715e-01,  ..., -2.1274e-01,\n",
            "          -7.5464e-01,  8.6993e-01],\n",
            "         [ 4.1657e-01, -8.0150e-01, -6.6618e-01,  ..., -6.2904e-02,\n",
            "          -1.1576e+00, -1.0248e-02],\n",
            "         ...,\n",
            "         [-5.5664e-01, -2.3661e+00, -2.0836e+00,  ...,  7.1032e-02,\n",
            "          -7.5541e-01,  6.4122e-01],\n",
            "         [-1.4157e-01, -3.9878e-01, -4.4164e-01,  ..., -4.3716e-01,\n",
            "           1.8317e-01, -2.5536e-01],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "        [[ 1.7867e+00, -2.8281e-01,  7.1723e-01,  ..., -6.4661e-01,\n",
            "           2.7737e+00, -1.2397e+00],\n",
            "         [ 1.1810e-01, -8.0549e-01, -6.7715e-01,  ..., -2.1274e-01,\n",
            "          -7.5464e-01,  8.6993e-01],\n",
            "         [-9.8533e-01, -8.0671e-01,  2.2452e+00,  ...,  2.8096e-02,\n",
            "           2.1516e-01, -1.5230e+00],\n",
            "         ...,\n",
            "         [ 6.0215e-01,  5.3312e-01,  8.3084e-01,  ...,  7.7363e-01,\n",
            "          -1.7840e+00,  2.5584e-01],\n",
            "         [-1.3565e+00,  4.2800e-02,  1.4724e+00,  ...,  1.3319e-01,\n",
            "           9.6653e-01, -8.5003e-02],\n",
            "         [-1.4157e-01, -3.9878e-01, -4.4164e-01,  ..., -4.3716e-01,\n",
            "           1.8317e-01, -2.5536e-01]],\n",
            "\n",
            "        [[ 1.7867e+00, -2.8281e-01,  7.1723e-01,  ..., -6.4661e-01,\n",
            "           2.7737e+00, -1.2397e+00],\n",
            "         [ 1.9473e-03, -1.3259e-01, -1.1721e-01,  ..., -1.2744e+00,\n",
            "          -8.6358e-02,  7.0297e-01],\n",
            "         [ 7.4645e-01, -4.2457e-01,  5.9870e-01,  ..., -3.9400e-01,\n",
            "           4.8636e-01,  1.3752e+00],\n",
            "         ...,\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "        [[ 1.7867e+00, -2.8281e-01,  7.1723e-01,  ..., -6.4661e-01,\n",
            "           2.7737e+00, -1.2397e+00],\n",
            "         [-2.4076e+00,  2.1164e-01, -1.2647e-02,  ...,  1.1064e+00,\n",
            "           1.4522e+00,  1.6282e-02],\n",
            "         [-7.4555e-01, -8.3810e-01, -1.7072e+00,  ..., -1.9693e+00,\n",
            "           5.8674e-01,  6.7279e-01],\n",
            "         ...,\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "        [[ 1.7867e+00, -2.8281e-01,  7.1723e-01,  ..., -6.4661e-01,\n",
            "           2.7737e+00, -1.2397e+00],\n",
            "         [-4.8261e-01, -5.5120e-01,  1.2558e-01,  ...,  1.4994e+00,\n",
            "          -1.0224e+00,  1.4757e+00],\n",
            "         [-3.7279e-01, -5.0755e-01,  1.2595e+00,  ..., -1.2028e+00,\n",
            "          -1.5954e-01, -1.2538e+00],\n",
            "         ...,\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           0.0000e+00,  0.0000e+00]]], grad_fn=<EmbeddingBackward0>)\n",
            "\n",
            "Position Embeddings:\n",
            " torch.Size([1, 25, 768])\n",
            "\n",
            "Position Embeddings:\n",
            " tensor([[[-0.9780,  1.5789, -0.3143,  ..., -0.6490,  0.6526,  1.5526],\n",
            "         [ 1.0990,  0.2102,  0.3735,  ...,  0.3675, -0.0397, -0.0259],\n",
            "         [-0.5032, -1.8981, -0.9689,  ...,  1.1441, -0.1320, -1.4503],\n",
            "         ...,\n",
            "         [ 0.4148, -1.1005, -0.3907,  ...,  0.6642, -0.2195,  0.9532],\n",
            "         [ 0.5538, -0.1807, -0.5534,  ...,  0.5610, -1.7184,  0.7187],\n",
            "         [ 0.9061, -1.1187, -0.2475,  ..., -0.3504, -0.5532, -1.4152]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Token Types Embeddings:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Token Types Embeddings:\n",
            " tensor([[[-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         ...,\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643]],\n",
            "\n",
            "        [[-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         ...,\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643]],\n",
            "\n",
            "        [[-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         ...,\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643]],\n",
            "\n",
            "        [[-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         ...,\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643]],\n",
            "\n",
            "        [[-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         ...,\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643],\n",
            "         [-0.5468, -0.4178, -1.0258,  ..., -1.5387, -0.9375,  1.5643]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "\n",
            "Sum Up All Embeddings:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Result:\n",
            " tensor([[[ 0.2619,  0.8784, -0.6228,  ..., -2.8344,  2.4889,  1.8772],\n",
            "         [ 0.6704, -1.0130, -1.3294,  ..., -1.3840, -1.7318,  2.4083],\n",
            "         [-0.6334, -3.1173, -2.6609,  ..., -0.4576, -2.2271,  0.1038],\n",
            "         ...,\n",
            "         [-0.6886, -3.8844, -3.5000,  ..., -0.8036, -1.9124,  3.1587],\n",
            "         [-0.1345, -0.9973, -2.0208,  ..., -1.4149, -2.4727,  2.0276],\n",
            "         [ 0.3593, -1.5364, -1.2732,  ..., -1.8891, -1.4907,  0.1491]],\n",
            "\n",
            "        [[ 0.2619,  0.8784, -0.6228,  ..., -2.8344,  2.4889,  1.8772],\n",
            "         [ 0.6704, -1.0130, -1.3294,  ..., -1.3840, -1.7318,  2.4083],\n",
            "         [-2.0353, -3.1225,  0.2506,  ..., -0.3666, -0.8543, -1.4090],\n",
            "         ...,\n",
            "         [ 0.4702, -0.9852, -0.5856,  ..., -0.1010, -2.9410,  2.7733],\n",
            "         [-1.3495, -0.5557, -0.1068,  ..., -0.8446, -1.6894,  2.1980],\n",
            "         [ 0.2177, -1.9352, -1.7149,  ..., -2.3263, -1.3075, -0.1063]],\n",
            "\n",
            "        [[ 0.2619,  0.8784, -0.6228,  ..., -2.8344,  2.4889,  1.8772],\n",
            "         [ 0.5542, -0.3401, -0.7695,  ..., -2.4456, -1.0636,  2.2414],\n",
            "         [-0.3035, -2.7404, -1.3960,  ..., -0.7887, -0.5831,  1.4892],\n",
            "         ...,\n",
            "         [-0.1320, -1.5183, -1.4165,  ..., -0.8746, -1.1570,  2.5175],\n",
            "         [ 0.0070, -0.5985, -1.5792,  ..., -0.9778, -2.6559,  2.2830],\n",
            "         [ 0.3593, -1.5364, -1.2732,  ..., -1.8891, -1.4907,  0.1491]],\n",
            "\n",
            "        [[ 0.2619,  0.8784, -0.6228,  ..., -2.8344,  2.4889,  1.8772],\n",
            "         [-1.8554,  0.0041, -0.6649,  ..., -0.0648,  0.4750,  1.5547],\n",
            "         [-1.7955, -3.1539, -3.7018,  ..., -2.3640, -0.4828,  0.7868],\n",
            "         ...,\n",
            "         [-0.1320, -1.5183, -1.4165,  ..., -0.8746, -1.1570,  2.5175],\n",
            "         [ 0.0070, -0.5985, -1.5792,  ..., -0.9778, -2.6559,  2.2830],\n",
            "         [ 0.3593, -1.5364, -1.2732,  ..., -1.8891, -1.4907,  0.1491]],\n",
            "\n",
            "        [[ 0.2619,  0.8784, -0.6228,  ..., -2.8344,  2.4889,  1.8772],\n",
            "         [ 0.0696, -0.7587, -0.5267,  ...,  0.3282, -1.9996,  3.0141],\n",
            "         [-1.4228, -2.8234, -0.7352,  ..., -1.5975, -1.2290, -1.1398],\n",
            "         ...,\n",
            "         [-0.1320, -1.5183, -1.4165,  ..., -0.8746, -1.1570,  2.5175],\n",
            "         [ 0.0070, -0.5985, -1.5792,  ..., -0.9778, -2.6559,  2.2830],\n",
            "         [ 0.3593, -1.5364, -1.2732,  ..., -1.8891, -1.4907,  0.1491]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "\n",
            "Embeddings Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Embeddings Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## build encoder"
      ],
      "metadata": {
        "id": "F6y9Gzc8UAns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### transformer paper"
      ],
      "metadata": {
        "id": "g-hs8phD_DkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def attention(query, key, value, mask=None, dropout=None):\n",
        "#     \"Compute 'Scaled Dot Product Attention'\"\n",
        "#     d_k = query.size(-1)\n",
        "#     scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "#     if mask is not None:\n",
        "#         scores = scores.masked_fill(mask == 0, -1e9)\n",
        "#     p_attn = scores.softmax(dim=-1)\n",
        "#     if dropout is not None:\n",
        "#         p_attn = dropout(p_attn)\n",
        "#     return torch.matmul(p_attn, value), p_attn"
      ],
      "metadata": {
        "id": "gBitegi72E0U"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class MultiHeadedAttention(nn.Module):\n",
        "#     def __init__(self, h, d_model, dropout=0.1):\n",
        "#         \"Take in model size and number of heads.\"\n",
        "#         super(MultiHeadedAttention, self).__init__()\n",
        "#         assert d_model % h == 0\n",
        "#         # We assume d_v always equals d_k\n",
        "#         self.d_k = d_model // h\n",
        "#         self.h = h\n",
        "#         self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "#         self.attn = None\n",
        "#         self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "#     def forward(self, query, key, value, mask=None):\n",
        "#         \"Implements Figure 2\"\n",
        "#         if mask is not None:\n",
        "#             # Same mask applied to all h heads.\n",
        "#             mask = mask.unsqueeze(1)\n",
        "#         nbatches = query.size(0)\n",
        "\n",
        "#         # 1) Do all the linear projections in batch from d_model => h x d_k\n",
        "#         query, key, value = [\n",
        "#             lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "#             for lin, x in zip(self.linears, (query, key, value))\n",
        "#         ]\n",
        "\n",
        "#         # 2) Apply attention on all the projected vectors in batch.\n",
        "#         x, self.attn = attention(\n",
        "#             query, key, value, mask=mask, dropout=self.dropout\n",
        "#         )\n",
        "\n",
        "#         # 3) \"Concat\" using a view and apply a final linear.\n",
        "#         x = (\n",
        "#             x.transpose(1, 2)\n",
        "#             .contiguous()\n",
        "#             .view(nbatches, -1, self.h * self.d_k)\n",
        "#         )\n",
        "#         del query\n",
        "#         del key\n",
        "#         del value\n",
        "#         return self.linears[-1](x)"
      ],
      "metadata": {
        "id": "Oe_XEzSs2NEU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def viz_encoder_self():\n",
        "#     model, example_data = run_model_example(n_examples=1)\n",
        "#     example = example_data[\n",
        "#         len(example_data) - 1\n",
        "#     ]  # batch object for the final example\n",
        "\n",
        "#     layer_viz = [\n",
        "#         visualize_layer(\n",
        "#             model, layer, get_encoder, len(example[1]), example[1], example[1]\n",
        "#         )\n",
        "#         for layer in range(6)\n",
        "#     ]\n",
        "#     return alt.hconcat(\n",
        "#         layer_viz[0]\n",
        "#         # & layer_viz[1]\n",
        "#         & layer_viz[2]\n",
        "#         # & layer_viz[3]\n",
        "#         & layer_viz[4]\n",
        "#         # & layer_viz[5]\n",
        "#     )\n",
        "\n",
        "\n",
        "# show_example(viz_encoder_self)"
      ],
      "metadata": {
        "id": "4STcMjHM3f7H"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self Attention and Self Output"
      ],
      "metadata": {
        "id": "dRr76LEs-_2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertSelfAttention(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
        "                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads)\n",
        "            )\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        # size of attention head\n",
        "        print('Attention Head Size:\\n', self.attention_head_size)\n",
        "        print('\\nCombined Attentions Head Size:\\n', self.all_head_size)\n",
        "        # linear Q K V\n",
        "        self.query = torch.nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = torch.nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = torch.nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        past_key_value=None,\n",
        "        output_attentions=False,\n",
        "    ):\n",
        "        print('\\nHidden States:\\n', hidden_states.shape)\n",
        "\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention and past_key_value is not None:\n",
        "\n",
        "            print('\\nQuery Linear Layer:\\n', mixed_query_layer.shape)\n",
        "            print('\\nKey Linear Layer:\\n', past_key_value[0].shape)\n",
        "            print('\\nValue Linear Layer:\\n', past_key_value[1].shape)\n",
        "\n",
        "            # reuse k,v, cross_attentions\n",
        "            key_layer = past_key_value[0]\n",
        "            value_layer = past_key_value[1]\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif is_cross_attention:\n",
        "\n",
        "            print('\\nQuery Linear Layer:\\n', mixed_query_layer.shape)\n",
        "            print('\\nKey Linear Layer:\\n', self.key(encoder_hidden_states).shape)\n",
        "            print('\\nValue Linear Layer:\\n', self.value(encoder_hidden_states).shape)\n",
        "\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif past_key_value is not None:\n",
        "\n",
        "            print('\\nQuery Linear Layer:\\n', mixed_query_layer.shape)\n",
        "            print('\\nKey Linear Layer:\\n', self.key(hidden_states).shape)\n",
        "            print('\\nValue Linear Layer:\\n', self.value(hidden_states).shape)\n",
        "\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "            key_layer = torch.cat([past_key_value[0], key_layer], dim=2)\n",
        "            value_layer = torch.cat([past_key_value[1], value_layer], dim=2)\n",
        "        else:\n",
        "\n",
        "            print('\\nQuery Linear Layer:\\n', mixed_query_layer.shape)\n",
        "            print('\\nKey Linear Layer:\\n', self.key(hidden_states).shape)\n",
        "            print('\\nValue Linear Layer:\\n', self.value(hidden_states).shape)\n",
        "\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        print('\\nQuery:\\n', query_layer.shape)\n",
        "        print('\\nKey:\\n', key_layer.shape)\n",
        "        print('\\nValue:\\n', value_layer.shape)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # transpose matrices\n",
        "        print('\\nKey Transposed:\\n', key_layer.transpose(-1, -2).shape)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        print('\\nAttention Scores:\\n', attention_scores.shape)\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            seq_length = hidden_states.size()[1]\n",
        "            position_ids_l = torch.arange(seq_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(seq_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        # divided by the dimension of the key vector sqrt of dk\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "\n",
        "        print('\\nAttention Scores Divided by Scalar:\\n', attention_scores.shape)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        # using softmax\n",
        "        attention_probs = torch.nn.Softmax(dim=-1)(attention_scores)\n",
        "\n",
        "        print('\\nAttention Probabilities Softmax Layer:\\n', attention_probs.shape)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        print('\\nAttention Probabilities Dropout Layer:\\n', attention_probs.shape)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        print('\\nContext:\\n', context_layer.shape)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        print('\\nContext Permute:\\n', context_layer.shape)\n",
        "\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "\n",
        "        print('\\nContext Reshaped:\\n', context_layer.shape)\n",
        "        \n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "# Create bert self attention layer.\n",
        "bert_selfattention_block = BertSelfAttention(config)\n",
        "\n",
        "# Perform a forward pass.\n",
        "context_embedding = bert_selfattention_block.forward(hidden_states=embedding_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJAiGg-M8rRX",
        "outputId": "32419049-4fe8-4399-d846-f2b4c05e99e2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertSelfOutput(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = torch.nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        print('Hidden States:\\n', hidden_states.shape)\n",
        "\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        print('\\nHidden States Linear Layer:\\n', hidden_states.shape)\n",
        "\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        print('\\nHidden States Dropout Layer:\\n', hidden_states.shape)\n",
        "\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        print('\\nHidden States Normalization Layer:\\n', hidden_states.shape)\n",
        "\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "# Create Bert self output layer.\n",
        "bert_selfoutput_block = BertSelfOutput(config)\n",
        "\n",
        "# Perform a forward pass - context_embedding[0] because we have tuple.\n",
        "attention_output = bert_selfoutput_block.forward(hidden_states=context_embedding[0], input_tensor=embedding_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDpy-Hdo_hfo",
        "outputId": "68705170-c810-4091-e70c-cb8e5f9f4a92"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT LAYER #1 Attention -> Self Attention + Output"
      ],
      "metadata": {
        "id": "EJxdUEebBqzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertAttention(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.self = BertSelfAttention(config)\n",
        "        self.output = BertSelfOutput(config)\n",
        "        self.pruned_heads = set()\n",
        "\n",
        "    def prune_heads(self, heads):\n",
        "        if len(heads) == 0:\n",
        "            return\n",
        "        heads, index = find_pruneable_heads_and_indices(\n",
        "            heads, self.self.num_attention_heads, self.self.attention_head_size, self.pruned_heads\n",
        "        )\n",
        "\n",
        "        # Prune linear layers\n",
        "        self.self.query = prune_linear_layer(self.self.query, index)\n",
        "        self.self.key = prune_linear_layer(self.self.key, index)\n",
        "        self.self.value = prune_linear_layer(self.self.value, index)\n",
        "        self.output.dense = prune_linear_layer(self.output.dense, index, dim=1)\n",
        "\n",
        "        # Update hyper params and store pruned heads\n",
        "        self.self.num_attention_heads = self.self.num_attention_heads - len(heads)\n",
        "        self.self.all_head_size = self.self.attention_head_size * self.self.num_attention_heads\n",
        "        self.pruned_heads = self.pruned_heads.union(heads)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        past_key_value=None,\n",
        "        output_attentions=False,\n",
        "    ):\n",
        "        self_outputs = self.self(\n",
        "            hidden_states,\n",
        "            attention_mask,\n",
        "            head_mask,\n",
        "            encoder_hidden_states,\n",
        "            encoder_attention_mask,\n",
        "            past_key_value,\n",
        "            output_attentions,\n",
        "        )\n",
        "        attention_output = self.output(self_outputs[0], hidden_states)\n",
        "        outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\n",
        "        return outputs\n",
        "\n",
        "# Create attention assembled layer.\n",
        "bert_attention_block = BertAttention(config)\n",
        "\n",
        "# Perform a forward pass to wholte Bert Attention layer.\n",
        "attention_output = bert_attention_block(hidden_states=embedding_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DXot8A8BpIU",
        "outputId": "545af13e-a03c-4bad-acbd-957c8807f835"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT LAYER #2 Intermediate: FFNN"
      ],
      "metadata": {
        "id": "qB_T7LOzC3uN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertIntermediate(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = torch.nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        print('\\nHidden States:\\n', hidden_states.shape)\n",
        "\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        print('\\nHidden States Linear Layer:\\n', hidden_states.shape)\n",
        "\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "        print('\\nHidden States Gelu Activation Function:\\n', hidden_states.shape)\n",
        "\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "# Create bert intermediate layer.\n",
        "bert_intermediate_block = BertIntermediate(config)\n",
        "\n",
        "# Perform a forward pass - attention_output[0] because we have tuple.\n",
        "intermediate_output = bert_intermediate_block.forward(hidden_states=attention_output[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTBu0FBTDOJT",
        "outputId": "53942f6b-f043-41f3-ab66-cec0c0ee9094"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT LAYER #3 Output: Add+Norm"
      ],
      "metadata": {
        "id": "c3FvVOQpDaQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertOutput(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = torch.nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        print('\\nHidden States:\\n', hidden_states.shape)\n",
        "\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        print('\\nHidden States Linear Layer:\\n', hidden_states.shape)\n",
        "\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        print('\\nHidden States Dropout Layer:\\n', hidden_states.shape)\n",
        "\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        print('\\nHidden States Layer Normalization:\\n', hidden_states.shape)\n",
        "\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "# Create bert output layer.\n",
        "bert_output_block = BertOutput(config)\n",
        "\n",
        "# Perform forward pass - attention_output[0] dealing with tuple.\n",
        "layer_output = bert_output_block.forward(hidden_states=intermediate_output, input_tensor=attention_output[0])\n"
      ],
      "metadata": {
        "outputId": "06d53f29-d66e-4b2e-ba08-1400e6ed7b3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QuRzAQcDaQ_"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[transformers inner workings](http://nlp.seas.harvard.edu/annotated-transformer/#positional-encoding)\n",
        "\n",
        "[bert inner workings](https://gmihaila.github.io/tutorial_notebooks/bert_inner_workings/)\n",
        "\n",
        "\n",
        "[bert visualization](https://colab.research.google.com/drive/1hXIQ77A4TYS4y3UthWF-Ci7V7vVUoxmQ?usp=sharing)"
      ],
      "metadata": {
        "id": "nx3twIhNcy4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Encoder: Self Attention - Multi-Head Attention"
      ],
      "metadata": {
        "id": "rshihYgwD2ax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self Attention"
      ],
      "metadata": {
        "id": "S3YmPw6wEFrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertLayer(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        self.seq_len_dim = 1\n",
        "        self.attention = BertAttention(config)\n",
        "        self.is_decoder = config.is_decoder\n",
        "        self.add_cross_attention = config.add_cross_attention\n",
        "        if self.add_cross_attention:\n",
        "            assert self.is_decoder, f\"{self} should be used as a decoder model if cross attention is added\"\n",
        "            self.crossattention = BertAttention(config)\n",
        "        self.intermediate = BertIntermediate(config)\n",
        "        self.output = BertOutput(config)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        past_key_value=None,\n",
        "        output_attentions=False,\n",
        "    ):\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "        self_attention_outputs = self.attention(\n",
        "            hidden_states,\n",
        "            attention_mask,\n",
        "            head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            past_key_value=self_attn_past_key_value,\n",
        "        )\n",
        "        attention_output = self_attention_outputs[0]\n",
        "\n",
        "        # if decoder, the last output is tuple of self-attn cache\n",
        "        if self.is_decoder:\n",
        "            outputs = self_attention_outputs[1:-1]\n",
        "            present_key_value = self_attention_outputs[-1]\n",
        "        else:\n",
        "            outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
        "\n",
        "        cross_attn_present_key_value = None\n",
        "        if self.is_decoder and encoder_hidden_states is not None:\n",
        "            assert hasattr(\n",
        "                self, \"crossattention\"\n",
        "            ), f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers by setting `config.add_cross_attention=True`\"\n",
        "\n",
        "            # cross_attn cached key/values tuple is at positions 3,4 of past_key_value tuple\n",
        "            cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None\n",
        "            cross_attention_outputs = self.crossattention(\n",
        "                attention_output,\n",
        "                attention_mask,\n",
        "                head_mask,\n",
        "                encoder_hidden_states,\n",
        "                encoder_attention_mask,\n",
        "                cross_attn_past_key_value,\n",
        "                output_attentions,\n",
        "            )\n",
        "            attention_output = cross_attention_outputs[0]\n",
        "            outputs = outputs + cross_attention_outputs[1:-1]  # add cross attentions if we output attention weights\n",
        "\n",
        "            # add cross-attn cache to positions 3,4 of present_key_value tuple\n",
        "            cross_attn_present_key_value = cross_attention_outputs[-1]\n",
        "            present_key_value = present_key_value + cross_attn_present_key_value\n",
        "\n",
        "        layer_output = apply_chunking_to_forward(\n",
        "            self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output\n",
        "        )\n",
        "        outputs = (layer_output,) + outputs\n",
        "\n",
        "        # if decoder, return the attn key/values as the last output\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (present_key_value,)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def feed_forward_chunk(self, attention_output):\n",
        "        intermediate_output = self.intermediate(attention_output)\n",
        "        layer_output = self.output(intermediate_output, attention_output)\n",
        "        return layer_output\n",
        "\n",
        "\n",
        "\n",
        "# Assemble block to create Bert Layer.\n",
        "bert_layer_block = BertLayer(config)\n",
        "\n",
        "# Perform feed forward on a whole Bert Layer.\n",
        "layer_output = bert_layer_block.forward(hidden_states=embedding_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEkHjRN7ELFi",
        "outputId": "8ae070cb-1bec-4b4d-fd5e-975261c6185d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Head Attention"
      ],
      "metadata": {
        "id": "KLmDLSl-EIkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertEncoder(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.layer = torch.nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        past_key_values=None,\n",
        "        use_cache=None,\n",
        "        output_attentions=False,\n",
        "        output_hidden_states=False,\n",
        "        return_dict=True,\n",
        "    ):\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_self_attentions = () if output_attentions else None\n",
        "        all_cross_attentions = () if output_attentions and self.config.add_cross_attention else None\n",
        "\n",
        "        next_decoder_cache = () if use_cache else None\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "\n",
        "            # ADDED\n",
        "            print('\\n----------------- BERT LAYER %d -----------------'%(i+1))\n",
        "\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
        "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
        "            if getattr(self.config, \"gradient_checkpointing\", False):\n",
        "\n",
        "                def create_custom_forward(module):\n",
        "                    def custom_forward(*inputs):\n",
        "                        return module(*inputs, past_key_value, output_attentions)\n",
        "\n",
        "                    return custom_forward\n",
        "\n",
        "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
        "                    create_custom_forward(layer_module),\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    layer_head_mask,\n",
        "                    encoder_hidden_states,\n",
        "                    encoder_attention_mask,\n",
        "                )\n",
        "            else:\n",
        "                layer_outputs = layer_module(\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    layer_head_mask,\n",
        "                    encoder_hidden_states,\n",
        "                    encoder_attention_mask,\n",
        "                    past_key_value,\n",
        "                    output_attentions,\n",
        "                )\n",
        "\n",
        "            hidden_states = layer_outputs[0]\n",
        "            if use_cache:\n",
        "                next_decoder_cache += (layer_outputs[-1],)\n",
        "            if output_attentions:\n",
        "                all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
        "                if self.config.add_cross_attention:\n",
        "                    all_cross_attentions = all_cross_attentions + (layer_outputs[2],)\n",
        "\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(\n",
        "                v\n",
        "                for v in [\n",
        "                    hidden_states,\n",
        "                    next_decoder_cache,\n",
        "                    all_hidden_states,\n",
        "                    all_self_attentions,\n",
        "                    all_cross_attentions,\n",
        "                ]\n",
        "                if v is not None\n",
        "            )\n",
        "        return BaseModelOutputWithPastAndCrossAttentions(\n",
        "            last_hidden_state=hidden_states,\n",
        "            past_key_values=next_decoder_cache,\n",
        "            hidden_states=all_hidden_states,\n",
        "            attentions=all_self_attentions,\n",
        "            cross_attentions=all_cross_attentions,\n",
        "        )\n",
        "\n",
        "# create bert encoder block by stacking 12 layers\n",
        "bert_encoder_block = BertEncoder(config)\n",
        "\n",
        "# perform forward pass on entire Bert Encoder\n",
        "encoder_embedding = bert_encoder_block.forward(hidden_states=embedding_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyVKtA6_Ehqj",
        "outputId": "00e60449-326c-4957-e69f-2112260f325e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "\n",
            "----------------- BERT LAYER 1 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 2 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 3 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 4 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 5 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 6 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 7 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 8 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 9 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 10 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 11 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 12 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Pooler"
      ],
      "metadata": {
        "id": "V2m8DTjtFCGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertPooler(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = torch.nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = torch.nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "       \n",
        "        print('\\nHidden States:\\n', hidden_states.shape)\n",
        "\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        print('\\nFirst Token [CLS]:\\n', first_token_tensor.shape)\n",
        "\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        print('\\nFirst Token [CLS] Linear Layer:\\n', pooled_output.shape)\n",
        "\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        print('\\nFirst Token [CLS] Tanh Activation Function:\\n', pooled_output.shape)\n",
        "\n",
        "        return pooled_output\n",
        "\n",
        "\n",
        "# Create bert pooler block.\n",
        "bert_pooler_block = BertPooler(config)\n",
        "\n",
        "# Perform forward pass - encoder_embedding[0] because it is a tuple.\n",
        "pooled_output = bert_pooler_block(hidden_states=encoder_embedding[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2YV2S2FFA66",
        "outputId": "3b7d7ef8-1342-4ab2-f5f6-c3fa12b855da"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "First Token [CLS]:\n",
            " torch.Size([5, 768])\n",
            "\n",
            "First Token [CLS] Linear Layer:\n",
            " torch.Size([5, 768])\n",
            "\n",
            "First Token [CLS] Tanh Activation Function:\n",
            " torch.Size([5, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Model: Encoder + Pooler"
      ],
      "metadata": {
        "id": "75jb3TaeFNpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertModel(BertPreTrainedModel):\n",
        "    \"\"\"\n",
        "    The model can behave as an encoder (with only self-attention) as well as a decoder, in which case a layer of\n",
        "    cross-attention is added between the self-attention layers, following the architecture described in `Attention is\n",
        "    all you need <https://arxiv.org/abs/1706.03762>`__ by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,\n",
        "    Llion Jones, Aidan N. Gomez, Lukasz Kaiser and Illia Polosukhin.\n",
        "    To behave as an decoder the model needs to be initialized with the :obj:`is_decoder` argument of the configuration\n",
        "    set to :obj:`True`. To be used in a Seq2Seq model, the model needs to initialized with both :obj:`is_decoder`\n",
        "    argument and :obj:`add_cross_attention` set to :obj:`True`; an :obj:`encoder_hidden_states` is then expected as an\n",
        "    input to the forward pass.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, add_pooling_layer=True):\n",
        "        super().__init__(config)\n",
        "        self.config = config\n",
        "\n",
        "        self.embeddings = BertEmbeddings(config)\n",
        "        self.encoder = BertEncoder(config)\n",
        "\n",
        "        self.pooler = BertPooler(config) if add_pooling_layer else None\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.embeddings.word_embeddings\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.embeddings.word_embeddings = value\n",
        "\n",
        "    def _prune_heads(self, heads_to_prune):\n",
        "        \"\"\"\n",
        "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
        "        class PreTrainedModel\n",
        "        \"\"\"\n",
        "        for layer, heads in heads_to_prune.items():\n",
        "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        past_key_values=None,\n",
        "        use_cache=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        encoder_hidden_states  (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n",
        "            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n",
        "            the model is configured as a decoder.\n",
        "        encoder_attention_mask (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
        "            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n",
        "            the cross-attention if the model is configured as a decoder. Mask values selected in ``[0, 1]``:\n",
        "            - 1 for tokens that are **not masked**,\n",
        "            - 0 for tokens that are **masked**.\n",
        "        past_key_values (:obj:`tuple(tuple(torch.FloatTensor))` of length :obj:`config.n_layers` with each tuple having 4 tensors of shape :obj:`(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
        "            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
        "            If :obj:`past_key_values` are used, the user can optionally input only the last :obj:`decoder_input_ids`\n",
        "            (those that don't have their past key value states given to this model) of shape :obj:`(batch_size, 1)`\n",
        "            instead of all :obj:`decoder_input_ids` of shape :obj:`(batch_size, sequence_length)`.\n",
        "        use_cache (:obj:`bool`, `optional`):\n",
        "            If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up\n",
        "            decoding (see :obj:`past_key_values`).\n",
        "        \"\"\"\n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if self.config.is_decoder:\n",
        "            use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "        else:\n",
        "            use_cache = False\n",
        "\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "            batch_size, seq_length = input_shape\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "            batch_size, seq_length = input_shape\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
        "\n",
        "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
        "\n",
        "        # past_key_values_length\n",
        "        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n",
        "\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape, device)\n",
        "\n",
        "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
        "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
        "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
        "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
        "            if encoder_attention_mask is None:\n",
        "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
        "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
        "        else:\n",
        "            encoder_extended_attention_mask = None\n",
        "\n",
        "        # Prepare head mask if needed\n",
        "        # 1.0 in head_mask indicate we keep the head\n",
        "        # attention_probs has shape bsz x n_heads x N x N\n",
        "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
        "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
        "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
        "\n",
        "        embedding_output = self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            past_key_values_length=past_key_values_length,\n",
        "        )\n",
        "        encoder_outputs = self.encoder(\n",
        "            embedding_output,\n",
        "            attention_mask=extended_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_extended_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
        "\n",
        "        if not return_dict:\n",
        "            return (sequence_output, pooled_output) + encoder_outputs[1:]\n",
        "\n",
        "        return BaseModelOutputWithPoolingAndCrossAttentions(\n",
        "            last_hidden_state=sequence_output,\n",
        "            pooler_output=pooled_output,\n",
        "            past_key_values=encoder_outputs.past_key_values,\n",
        "            hidden_states=encoder_outputs.hidden_states,\n",
        "            attentions=encoder_outputs.attentions,\n",
        "            cross_attentions=encoder_outputs.cross_attentions,\n",
        "        )\n",
        "\n",
        "\n",
        "# Create bert model.\n",
        "bert_model = BertModel(config)\n",
        "\n",
        "# Perform forward pass on entire model.\n",
        "hidden_states = bert_model.forward(input_ids=input_sequences['input_ids'], attention_mask=input_sequences['attention_mask'], token_type_ids=input_sequences['token_type_ids'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Yi2W1YtCFM4U",
        "outputId": "ac11c07c-2b08-459f-ad3a-35a103623745"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/modeling_utils.py:830: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created Tokens Positions IDs:\n",
            " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "         18, 19, 20, 21, 22, 23, 24]])\n",
            "\n",
            "Tokens IDs shape:\n",
            " torch.Size([5, 25])\n",
            "\n",
            "Tokens IDs:\n",
            " tensor([[    2,  7229,  8181,  4302,  1107, 12006,    94,  8074,  1614, 30378,\n",
            "         30468,  1766, 10357,   804,  1107,  7132, 30470,   895,  5222,    26,\n",
            "           795,   421, 30470,     3,     0],\n",
            "        [    2,  7229,  3107, 30468,  1622,    57,  3107,  3478,  3027,    57,\n",
            "          2105, 30052,  2692,  5633, 30470,  1012,   118,  1966, 30468,   525,\n",
            "         10263,    43,  2377,   423,     3],\n",
            "        [    2,   515, 16503,  4881,  6943, 30354,  2174,  2382,  1966,   968,\n",
            "         19287,    22,     3,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0],\n",
            "        [    2,  2839,  1990,    41,  1349,  1771,  1876,  2234,  3346, 30378,\n",
            "         11105,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0],\n",
            "        [    2,  2040,  1686,    90,   494,   158, 19287,    22,     3,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0]])\n",
            "\n",
            "Tokens Type IDs shape:\n",
            " torch.Size([5, 25])\n",
            "\n",
            "Tokens Type IDs / Segments:\n",
            " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0]])\n",
            "\n",
            "Word Embeddings shape:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Word Embeddings #1:\n",
            " tensor([[[ 0.0050,  0.0011, -0.0376,  ...,  0.0262, -0.0312, -0.0044],\n",
            "         [ 0.0053,  0.0121, -0.0012,  ...,  0.0133,  0.0118, -0.0207],\n",
            "         [ 0.0333, -0.0288, -0.0160,  ..., -0.0154,  0.0177,  0.0057],\n",
            "         ...,\n",
            "         [-0.0032, -0.0161,  0.0087,  ..., -0.0079,  0.0280, -0.0113],\n",
            "         [-0.0158, -0.0059, -0.0144,  ...,  0.0058, -0.0046,  0.0107],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0050,  0.0011, -0.0376,  ...,  0.0262, -0.0312, -0.0044],\n",
            "         [ 0.0053,  0.0121, -0.0012,  ...,  0.0133,  0.0118, -0.0207],\n",
            "         [ 0.0081,  0.0208,  0.0136,  ..., -0.0035, -0.0243,  0.0179],\n",
            "         ...,\n",
            "         [-0.0341, -0.0064, -0.0082,  ..., -0.0273,  0.0170,  0.0186],\n",
            "         [-0.0198, -0.0063,  0.0135,  ..., -0.0184,  0.0042,  0.0040],\n",
            "         [-0.0158, -0.0059, -0.0144,  ...,  0.0058, -0.0046,  0.0107]],\n",
            "\n",
            "        [[ 0.0050,  0.0011, -0.0376,  ...,  0.0262, -0.0312, -0.0044],\n",
            "         [ 0.0192, -0.0286, -0.0056,  ...,  0.0222, -0.0164, -0.0152],\n",
            "         [-0.0136,  0.0454, -0.0125,  ..., -0.0050,  0.0167,  0.0049],\n",
            "         ...,\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0050,  0.0011, -0.0376,  ...,  0.0262, -0.0312, -0.0044],\n",
            "         [ 0.0050,  0.0054,  0.0157,  ..., -0.0223,  0.0437,  0.0065],\n",
            "         [-0.0168,  0.0385,  0.0163,  ...,  0.0091,  0.0101,  0.0154],\n",
            "         ...,\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0050,  0.0011, -0.0376,  ...,  0.0262, -0.0312, -0.0044],\n",
            "         [-0.0059,  0.0099, -0.0121,  ...,  0.0175,  0.0114,  0.0267],\n",
            "         [-0.0206, -0.0166, -0.0191,  ..., -0.0006, -0.0346, -0.0080],\n",
            "         ...,\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "\n",
            "Position Embeddings:\n",
            " torch.Size([1, 25, 768])\n",
            "\n",
            "Position Embeddings:\n",
            " tensor([[[ 0.0272, -0.0101, -0.0382,  ...,  0.0088,  0.0003,  0.0194],\n",
            "         [-0.0198, -0.0120,  0.0026,  ...,  0.0160,  0.0416, -0.0145],\n",
            "         [ 0.0204,  0.0222,  0.0116,  ...,  0.0043,  0.0022,  0.0237],\n",
            "         ...,\n",
            "         [ 0.0003, -0.0158,  0.0302,  ...,  0.0058, -0.0316, -0.0257],\n",
            "         [-0.0290, -0.0268,  0.0147,  ..., -0.0238, -0.0044,  0.0168],\n",
            "         [ 0.0036,  0.0029,  0.0016,  ...,  0.0070,  0.0147,  0.0192]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Token Types Embeddings:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Token Types Embeddings:\n",
            " tensor([[[-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         ...,\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261]],\n",
            "\n",
            "        [[-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         ...,\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261]],\n",
            "\n",
            "        [[-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         ...,\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261]],\n",
            "\n",
            "        [[-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         ...,\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261]],\n",
            "\n",
            "        [[-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         ...,\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261],\n",
            "         [-0.0297, -0.0425,  0.0011,  ...,  0.0337,  0.0008, -0.0261]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "\n",
            "Sum Up All Embeddings:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Result:\n",
            " tensor([[[ 0.0025, -0.0515, -0.0747,  ...,  0.0687, -0.0302, -0.0112],\n",
            "         [-0.0442, -0.0425,  0.0026,  ...,  0.0630,  0.0542, -0.0613],\n",
            "         [ 0.0240, -0.0491, -0.0033,  ...,  0.0226,  0.0207,  0.0033],\n",
            "         ...,\n",
            "         [-0.0326, -0.0744,  0.0400,  ...,  0.0316, -0.0027, -0.0631],\n",
            "         [-0.0746, -0.0753,  0.0014,  ...,  0.0157, -0.0082,  0.0014],\n",
            "         [-0.0261, -0.0397,  0.0028,  ...,  0.0407,  0.0155, -0.0069]],\n",
            "\n",
            "        [[ 0.0025, -0.0515, -0.0747,  ...,  0.0687, -0.0302, -0.0112],\n",
            "         [-0.0442, -0.0425,  0.0026,  ...,  0.0630,  0.0542, -0.0613],\n",
            "         [-0.0012,  0.0005,  0.0263,  ...,  0.0344, -0.0213,  0.0156],\n",
            "         ...,\n",
            "         [-0.0635, -0.0647,  0.0231,  ...,  0.0123, -0.0138, -0.0332],\n",
            "         [-0.0786, -0.0757,  0.0294,  ..., -0.0085,  0.0006, -0.0053],\n",
            "         [-0.0419, -0.0456, -0.0117,  ...,  0.0464,  0.0109,  0.0038]],\n",
            "\n",
            "        [[ 0.0025, -0.0515, -0.0747,  ...,  0.0687, -0.0302, -0.0112],\n",
            "         [-0.0304, -0.0831, -0.0019,  ...,  0.0718,  0.0259, -0.0558],\n",
            "         [-0.0230,  0.0251,  0.0002,  ...,  0.0329,  0.0197,  0.0026],\n",
            "         ...,\n",
            "         [-0.0295, -0.0583,  0.0313,  ...,  0.0395, -0.0308, -0.0518],\n",
            "         [-0.0588, -0.0694,  0.0159,  ...,  0.0099, -0.0036, -0.0093],\n",
            "         [-0.0261, -0.0397,  0.0028,  ...,  0.0407,  0.0155, -0.0069]],\n",
            "\n",
            "        [[ 0.0025, -0.0515, -0.0747,  ...,  0.0687, -0.0302, -0.0112],\n",
            "         [-0.0446, -0.0491,  0.0194,  ...,  0.0273,  0.0861, -0.0341],\n",
            "         [-0.0261,  0.0182,  0.0290,  ...,  0.0470,  0.0131,  0.0130],\n",
            "         ...,\n",
            "         [-0.0295, -0.0583,  0.0313,  ...,  0.0395, -0.0308, -0.0518],\n",
            "         [-0.0588, -0.0694,  0.0159,  ...,  0.0099, -0.0036, -0.0093],\n",
            "         [-0.0261, -0.0397,  0.0028,  ...,  0.0407,  0.0155, -0.0069]],\n",
            "\n",
            "        [[ 0.0025, -0.0515, -0.0747,  ...,  0.0687, -0.0302, -0.0112],\n",
            "         [-0.0555, -0.0447, -0.0084,  ...,  0.0671,  0.0537, -0.0139],\n",
            "         [-0.0299, -0.0369, -0.0064,  ...,  0.0373, -0.0316, -0.0104],\n",
            "         ...,\n",
            "         [-0.0295, -0.0583,  0.0313,  ...,  0.0395, -0.0308, -0.0518],\n",
            "         [-0.0588, -0.0694,  0.0159,  ...,  0.0099, -0.0036, -0.0093],\n",
            "         [-0.0261, -0.0397,  0.0028,  ...,  0.0407,  0.0155, -0.0069]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "\n",
            "Embeddings Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Embeddings Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 1 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 2 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 3 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 4 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 5 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 6 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 7 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 8 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 9 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 10 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 11 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 12 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "First Token [CLS]:\n",
            " torch.Size([5, 768])\n",
            "\n",
            "First Token [CLS] Linear Layer:\n",
            " torch.Size([5, 768])\n",
            "\n",
            "First Token [CLS] Tanh Activation Function:\n",
            " torch.Size([5, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Multi-Label Classification Model"
      ],
      "metadata": {
        "id": "wYuZHvQpF6H5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForMultiLabelClassification(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels_list\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifiers = nn.ModuleList([nn.Linear(config.hidden_size, num_label) for num_label in self.num_labels])\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        subword_to_word_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`, defaults to :obj:`None`):\n",
        "            Labels for computing the token classification loss.\n",
        "            Indices should be in ``[0, ..., config.num_labels - 1]``.\n",
        "    Returns:\n",
        "        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.BertConfig`) and inputs:\n",
        "        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when ``labels`` is provided) :\n",
        "            Classification loss.\n",
        "        scores (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, config.num_labels)`)\n",
        "            Classification scores (before SoftMax).\n",
        "        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n",
        "            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n",
        "            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
        "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
        "        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n",
        "            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n",
        "            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n",
        "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
        "            heads.\n",
        "        \"\"\"\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        sequence_output = self.dropout(outputs[1])\n",
        "        logits = []\n",
        "        for classifier in self.classifiers:\n",
        "            logit = classifier(sequence_output)\n",
        "            logits.append(logit)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            total_loss = 0\n",
        "            for i, (logit, num_label) in enumerate(zip(logits, self.num_labels)):\n",
        "                label = labels[:,i]\n",
        "                loss = loss_fct(logit.view(-1, num_label), label.view(-1))\n",
        "                total_loss += loss\n",
        "            outputs = (total_loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), scores, (hidden_states), (attentions)"
      ],
      "metadata": {
        "id": "VI5QM_77HUpD"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create Bert model with classification layer - BertForSequenceClassificatin\n",
        "bert_for_multilabel_classification_model = BertForMultiLabelClassification(config)\n",
        "\n",
        "# perform forward pass on entire model\n",
        "outputs = bert_for_multilabel_classification_model(**input_sequences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i7UK_3YaHcYU",
        "outputId": "94745e45-9894-42d3-9d48-1472d9fee5d8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n",
            "Attention Head Size:\n",
            " 64\n",
            "\n",
            "Combined Attentions Head Size:\n",
            " 768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/modeling_utils.py:830: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created Tokens Positions IDs:\n",
            " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "         18, 19, 20, 21, 22, 23, 24]])\n",
            "\n",
            "Tokens IDs shape:\n",
            " torch.Size([5, 25])\n",
            "\n",
            "Tokens IDs:\n",
            " tensor([[    2,  7229,  8181,  4302,  1107, 12006,    94,  8074,  1614, 30378,\n",
            "         30468,  1766, 10357,   804,  1107,  7132, 30470,   895,  5222,    26,\n",
            "           795,   421, 30470,     3,     0],\n",
            "        [    2,  7229,  3107, 30468,  1622,    57,  3107,  3478,  3027,    57,\n",
            "          2105, 30052,  2692,  5633, 30470,  1012,   118,  1966, 30468,   525,\n",
            "         10263,    43,  2377,   423,     3],\n",
            "        [    2,   515, 16503,  4881,  6943, 30354,  2174,  2382,  1966,   968,\n",
            "         19287,    22,     3,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0],\n",
            "        [    2,  2839,  1990,    41,  1349,  1771,  1876,  2234,  3346, 30378,\n",
            "         11105,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0],\n",
            "        [    2,  2040,  1686,    90,   494,   158, 19287,    22,     3,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0]])\n",
            "\n",
            "Tokens Type IDs shape:\n",
            " torch.Size([5, 25])\n",
            "\n",
            "Tokens Type IDs / Segments:\n",
            " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0]])\n",
            "\n",
            "Word Embeddings shape:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Word Embeddings #1:\n",
            " tensor([[[ 0.0161, -0.0266,  0.0116,  ...,  0.0240, -0.0313, -0.0529],\n",
            "         [ 0.0691, -0.0002,  0.0130,  ...,  0.0058,  0.0038, -0.0021],\n",
            "         [-0.0702, -0.0161, -0.0025,  ..., -0.0103, -0.0277,  0.0036],\n",
            "         ...,\n",
            "         [ 0.0321, -0.0130, -0.0152,  ..., -0.0371, -0.0132,  0.0104],\n",
            "         [-0.0392, -0.0050,  0.0280,  ..., -0.0211, -0.0181, -0.0063],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0161, -0.0266,  0.0116,  ...,  0.0240, -0.0313, -0.0529],\n",
            "         [ 0.0691, -0.0002,  0.0130,  ...,  0.0058,  0.0038, -0.0021],\n",
            "         [-0.0158,  0.0067,  0.0133,  ..., -0.0077,  0.0449, -0.0014],\n",
            "         ...,\n",
            "         [ 0.0400,  0.0225,  0.0150,  ...,  0.0021,  0.0364,  0.0006],\n",
            "         [-0.0247,  0.0051, -0.0148,  ...,  0.0219,  0.0106,  0.0091],\n",
            "         [-0.0392, -0.0050,  0.0280,  ..., -0.0211, -0.0181, -0.0063]],\n",
            "\n",
            "        [[ 0.0161, -0.0266,  0.0116,  ...,  0.0240, -0.0313, -0.0529],\n",
            "         [-0.0123,  0.0020, -0.0327,  ...,  0.0246, -0.0538,  0.0061],\n",
            "         [ 0.0349, -0.0137, -0.0321,  ...,  0.0246, -0.0015, -0.0496],\n",
            "         ...,\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0161, -0.0266,  0.0116,  ...,  0.0240, -0.0313, -0.0529],\n",
            "         [ 0.0216, -0.0048, -0.0010,  ..., -0.0391,  0.0314, -0.0180],\n",
            "         [ 0.0525, -0.0482, -0.0251,  ...,  0.0225,  0.0164, -0.0128],\n",
            "         ...,\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[ 0.0161, -0.0266,  0.0116,  ...,  0.0240, -0.0313, -0.0529],\n",
            "         [ 0.0088,  0.0018,  0.0315,  ..., -0.0210,  0.0200,  0.0281],\n",
            "         [-0.0119, -0.0043,  0.0039,  ...,  0.0006,  0.0156, -0.0314],\n",
            "         ...,\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "\n",
            "Position Embeddings:\n",
            " torch.Size([1, 25, 768])\n",
            "\n",
            "Position Embeddings:\n",
            " tensor([[[ 0.0016,  0.0118,  0.0217,  ..., -0.0098, -0.0051, -0.0166],\n",
            "         [ 0.0070, -0.0237,  0.0080,  ...,  0.0078,  0.0195, -0.0049],\n",
            "         [ 0.0081,  0.0060, -0.0111,  ..., -0.0093,  0.0335,  0.0085],\n",
            "         ...,\n",
            "         [ 0.0223,  0.0111, -0.0032,  ...,  0.0062, -0.0139,  0.0307],\n",
            "         [ 0.0237,  0.0148,  0.0182,  ..., -0.0091, -0.0181, -0.0059],\n",
            "         [-0.0303, -0.0049,  0.0022,  ..., -0.0090, -0.0134,  0.0153]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Token Types Embeddings:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Token Types Embeddings:\n",
            " tensor([[[ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         ...,\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032]],\n",
            "\n",
            "        [[ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         ...,\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032]],\n",
            "\n",
            "        [[ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         ...,\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032]],\n",
            "\n",
            "        [[ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         ...,\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032]],\n",
            "\n",
            "        [[ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         ...,\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032],\n",
            "         [ 0.0186, -0.0042,  0.0011,  ...,  0.0175, -0.0022,  0.0032]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "\n",
            "Sum Up All Embeddings:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Result:\n",
            " tensor([[[ 0.0363, -0.0191,  0.0344,  ...,  0.0316, -0.0386, -0.0662],\n",
            "         [ 0.0947, -0.0281,  0.0221,  ...,  0.0311,  0.0211, -0.0037],\n",
            "         [-0.0435, -0.0144, -0.0125,  ..., -0.0022,  0.0036,  0.0153],\n",
            "         ...,\n",
            "         [ 0.0730, -0.0061, -0.0174,  ..., -0.0134, -0.0293,  0.0443],\n",
            "         [ 0.0031,  0.0056,  0.0474,  ..., -0.0128, -0.0384, -0.0089],\n",
            "         [-0.0117, -0.0091,  0.0033,  ...,  0.0085, -0.0156,  0.0185]],\n",
            "\n",
            "        [[ 0.0363, -0.0191,  0.0344,  ...,  0.0316, -0.0386, -0.0662],\n",
            "         [ 0.0947, -0.0281,  0.0221,  ...,  0.0311,  0.0211, -0.0037],\n",
            "         [ 0.0109,  0.0084,  0.0033,  ...,  0.0004,  0.0762,  0.0103],\n",
            "         ...,\n",
            "         [ 0.0809,  0.0294,  0.0128,  ...,  0.0257,  0.0203,  0.0345],\n",
            "         [ 0.0176,  0.0157,  0.0045,  ...,  0.0302, -0.0096,  0.0064],\n",
            "         [-0.0509, -0.0141,  0.0314,  ..., -0.0126, -0.0337,  0.0122]],\n",
            "\n",
            "        [[ 0.0363, -0.0191,  0.0344,  ...,  0.0316, -0.0386, -0.0662],\n",
            "         [ 0.0133, -0.0259, -0.0236,  ...,  0.0498, -0.0365,  0.0044],\n",
            "         [ 0.0616, -0.0120, -0.0421,  ...,  0.0327,  0.0298, -0.0379],\n",
            "         ...,\n",
            "         [ 0.0409,  0.0069, -0.0021,  ...,  0.0236, -0.0161,  0.0339],\n",
            "         [ 0.0423,  0.0106,  0.0193,  ...,  0.0083, -0.0203, -0.0027],\n",
            "         [-0.0117, -0.0091,  0.0033,  ...,  0.0085, -0.0156,  0.0185]],\n",
            "\n",
            "        [[ 0.0363, -0.0191,  0.0344,  ...,  0.0316, -0.0386, -0.0662],\n",
            "         [ 0.0472, -0.0327,  0.0081,  ..., -0.0139,  0.0487, -0.0197],\n",
            "         [ 0.0792, -0.0465, -0.0351,  ...,  0.0306,  0.0477, -0.0011],\n",
            "         ...,\n",
            "         [ 0.0409,  0.0069, -0.0021,  ...,  0.0236, -0.0161,  0.0339],\n",
            "         [ 0.0423,  0.0106,  0.0193,  ...,  0.0083, -0.0203, -0.0027],\n",
            "         [-0.0117, -0.0091,  0.0033,  ...,  0.0085, -0.0156,  0.0185]],\n",
            "\n",
            "        [[ 0.0363, -0.0191,  0.0344,  ...,  0.0316, -0.0386, -0.0662],\n",
            "         [ 0.0344, -0.0261,  0.0406,  ...,  0.0042,  0.0373,  0.0265],\n",
            "         [ 0.0148, -0.0025, -0.0061,  ...,  0.0087,  0.0469, -0.0197],\n",
            "         ...,\n",
            "         [ 0.0409,  0.0069, -0.0021,  ...,  0.0236, -0.0161,  0.0339],\n",
            "         [ 0.0423,  0.0106,  0.0193,  ...,  0.0083, -0.0203, -0.0027],\n",
            "         [-0.0117, -0.0091,  0.0033,  ...,  0.0085, -0.0156,  0.0185]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "\n",
            "Embeddings Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Embeddings Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 1 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 2 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 3 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 4 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 5 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 6 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 7 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 8 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 9 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 10 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 11 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "----------------- BERT LAYER 12 -----------------\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Key Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Value Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Query:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Value:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Key Transposed:\n",
            " torch.Size([5, 12, 64, 25])\n",
            "\n",
            "Attention Scores:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Scores Divided by Scalar:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Softmax Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Attention Probabilities Dropout Layer:\n",
            " torch.Size([5, 12, 25, 25])\n",
            "\n",
            "Context:\n",
            " torch.Size([5, 12, 25, 64])\n",
            "\n",
            "Context Permute:\n",
            " torch.Size([5, 25, 12, 64])\n",
            "\n",
            "Context Reshaped:\n",
            " torch.Size([5, 25, 768])\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Normalization Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Gelu Activation Function:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 3072])\n",
            "\n",
            "Hidden States Linear Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Dropout Layer:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States Layer Normalization:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "Hidden States:\n",
            " torch.Size([5, 25, 768])\n",
            "\n",
            "First Token [CLS]:\n",
            " torch.Size([5, 768])\n",
            "\n",
            "First Token [CLS] Linear Layer:\n",
            " torch.Size([5, 768])\n",
            "\n",
            "First Token [CLS] Tanh Activation Function:\n",
            " torch.Size([5, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sources\n"
      ],
      "metadata": {
        "id": "g3WaonyybWGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "http://nlp.seas.harvard.edu/annotated-transformer/#positional-encoding\n",
        "\n",
        "https://gmihaila.github.io/tutorial_notebooks/bert_inner_workings/\n",
        "\n",
        "https://colab.research.google.com/drive/1hXIQ77A4TYS4y3UthWF-Ci7V7vVUoxmQ?usp=sharing\n"
      ],
      "metadata": {
        "id": "qQeIkh5tIIKp"
      }
    }
  ]
}